{"id":"engram-0lr","title":"Retroactive Enrichment on Subspace Update","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-24T09:33:14.967056+01:00","updated_at":"2026-02-24T09:33:14.967056+01:00"}
{"id":"engram-0ro","title":"Validation suite: golden tests + regression benchmarks","description":"Comprehensive validation suite: golden tests, regression, benchmarks:\n\n**Test structure:**\ntests/\n  ├── unit/ (9 files)\n  │   ├── vault-writer.test.ts — File creation, atomic writes, folder structure\n  │   ├── vault-reader.test.ts — Parse frontmatter, handle malformed YAML\n  │   ├── vault-reconciler.test.ts — Three-way merge, conflict detection\n  │   ├── wiki-link-parser.test.ts — Extract links, edge cases\n  │   ├── auto-linker.test.ts — Entity matching, duplicate avoidance\n  │   ├── vault-indexer.test.ts — Index generation, sorting\n  │   ├── budget-aware-loader.test.ts — Token counting, tier allocation\n  │   ├── frontmatter-generator.test.ts — All fact types, valid YAML\n  │   └── slug-generator.test.ts — Filename sanitization\n  ├── integration/ (7 files)\n  │   ├── write-through-e2e.test.ts — Store fact → file appears \u003c5s\n  │   ├── reconcile-e2e.test.ts — Edit file → DB updates\n  │   ├── conflict-e2e.test.ts — Concurrent edits → conflict file\n  │   ├── auto-linking-e2e.test.ts — Entity mentions → wiki-links\n  │   ├── index-first-e2e.test.ts — Query → index scan → results\n  │   ├── observation-compression-e2e.test.ts — Classify → compress\n  │   └── budget-aware-context-e2e.test.ts — Budget enforcement\n  ├── golden/ (4 files)\n  │   ├── format/decision.golden.md — Expected markdown for decision\n  │   ├── format/lesson.golden.md — Expected markdown for lesson\n  │   ├── format/entity.golden.md — Expected markdown for entity\n  │   └── retrieval/evaluate-relevance.test.ts — Query set, relevance@5\n  ├── benchmarks/ (1 file)\n  │   └── before-after.test.ts — Latency, relevance, token efficiency\n  └── regression/ (5 files)\n      ├── core-api.test.ts — All MCP tools still work\n      ├── enrichment.test.ts — Embeddings, entities, importance\n      ├── decay.test.ts — Decay cron still runs\n      ├── consolidation.test.ts — Theme merging still works\n      └── sync.test.ts — LanceDB sync still works\n\n**Golden query set (in retrieval/):**\n- 20+ queries with expected fact IDs\n- Min relevance thresholds per query\n- Cover all fact types and priority tiers\n\n**Performance benchmarks:**\n- Retrieval latency: before (450ms) vs after (\u003c200ms index, \u003c500ms semantic)\n- Relevance@5: before (0.72) vs after (\u003e0.85)\n- Token efficiency: before (2000) vs after (\u003c1400)\n- Sync reliability: 99.99% over 10k ops\n\n**CI Integration:**\n- Run on every PR, block merge if fails\n- Coverage target \u003e80%\n- Performance regression gate: \u003e10% slower = fail\n\nRef: VAULT_INTEGRATION_PLAN.md Phase 8 (sections 8.3-8.9)","status":"closed","priority":4,"issue_type":"task","created_at":"2026-02-14T22:57:11.869078+01:00","updated_at":"2026-02-14T23:25:57.557919+01:00","closed_at":"2026-02-14T23:25:57.557919+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-0ro","depends_on_id":"engram-dxj","type":"blocks","created_at":"2026-02-14T22:57:25.38331+01:00","created_by":"daemon"}]}
{"id":"engram-0wc","title":"Observability and production operations readiness","description":"Implement remaining operations hardening tasks: health check endpoint/tooling, structured logging standardization, enrichment/vault-lag telemetry hooks, and optional metrics scaffolding. Document alert thresholds and incident triage flow consistent with deployment checklist.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T00:33:58.532486+01:00","updated_at":"2026-02-15T00:49:13.001202+01:00","closed_at":"2026-02-15T00:49:13.001202+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-0wc","depends_on_id":"engram-hx4","type":"blocks","created_at":"2026-02-15T00:34:11.579734+01:00","created_by":"daemon"}]}
{"id":"engram-140","title":"Token Budget on Recall Responses","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-24T09:33:12.859294+01:00","updated_at":"2026-02-24T09:33:12.859294+01:00"}
{"id":"engram-17d","title":"Implement config resolver library","description":"Create convex/lib/config-resolver.ts with resolveConfig function. Priority: scope policy \u003e system config \u003e fallback. Add caching layer for \u003c1ms p99 lookups","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:23.031362+01:00","updated_at":"2026-02-15T00:47:30.955371+01:00","closed_at":"2026-02-15T00:47:30.955371+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-17d","depends_on_id":"engram-26p","type":"blocks","created_at":"2026-02-15T00:38:56.099535+01:00","created_by":"daemon"}]}
{"id":"engram-1le","title":"Phase 3: Real-Time \u0026 Identity","description":"Add memory_events table for streaming updates. Implement event polling tool with watermark-based pagination. Create agent identity context injection tool. Update enrichment pipeline to emit events.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-15T00:38:10.294183+01:00","updated_at":"2026-02-15T00:58:51.248092+01:00","closed_at":"2026-02-15T00:58:51.248092+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-1le","depends_on_id":"engram-qcu","type":"blocks","created_at":"2026-02-15T00:39:14.186016+01:00","created_by":"daemon"},{"issue_id":"engram-1le","depends_on_id":"engram-34c","type":"blocks","created_at":"2026-02-15T00:39:15.102871+01:00","created_by":"daemon"},{"issue_id":"engram-1le","depends_on_id":"engram-25m","type":"blocks","created_at":"2026-02-15T00:39:15.516796+01:00","created_by":"daemon"},{"issue_id":"engram-1le","depends_on_id":"engram-tsn","type":"blocks","created_at":"2026-02-15T00:39:16.052089+01:00","created_by":"daemon"}]}
{"id":"engram-1vx","title":"Add backwards compatibility wrappers","description":"Keep old tool names as thin wrappers over new primitives. Add deprecation warnings. Update mcp-server/src/tools/recall.ts and get-context.ts to compose primitives","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:38:36.682242+01:00","updated_at":"2026-02-15T00:58:50.439207+01:00","closed_at":"2026-02-15T00:58:50.439207+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-1vx","depends_on_id":"engram-dt4","type":"blocks","created_at":"2026-02-15T00:39:06.179401+01:00","created_by":"daemon"},{"issue_id":"engram-1vx","depends_on_id":"engram-95y","type":"blocks","created_at":"2026-02-15T00:39:06.581751+01:00","created_by":"daemon"},{"issue_id":"engram-1vx","depends_on_id":"engram-vgb","type":"blocks","created_at":"2026-02-15T00:39:07.008382+01:00","created_by":"daemon"}]}
{"id":"engram-1wl","title":"Complete context injection and agent identity tools","description":"Extend memory_get_context with explicit agentContext payload including agent metadata, telos, capabilities, permitted scopes, and current policy hints. Add memory_get_agent_info tool and optional memory_get_system_prompt tool for discoverability. Ensure tool descriptions are user-centric and include usage examples for composition patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:54.34893+01:00","updated_at":"2026-02-15T00:47:31.137386+01:00","closed_at":"2026-02-15T00:47:31.137386+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-1wl","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:07.061292+01:00","created_by":"daemon"}]}
{"id":"engram-25m","title":"Create agent identity context tool","description":"Build memory_get_agent_context tool returning agent metadata (name, telos, capabilities, settings), permitted scopes with policies, and system health (sync status, queue depth)","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:42.527926+01:00","updated_at":"2026-02-15T00:58:49.623018+01:00","closed_at":"2026-02-15T00:58:49.623018+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-25m","depends_on_id":"engram-c48","type":"blocks","created_at":"2026-02-15T00:39:12.808445+01:00","created_by":"daemon"}]}
{"id":"engram-26p","title":"Create config schema tables","description":"Add system_config table (key, value, category, description, version, updatedAt, updatedBy) and memory_policies table (scopeId, policyKey, policyValue, priority) to convex/schema.ts with proper indices","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:21.411995+01:00","updated_at":"2026-02-15T00:45:34.3061+01:00","closed_at":"2026-02-15T00:45:34.3061+01:00","close_reason":"Closed"}
{"id":"engram-2ui","title":"Obsidian-Compatible Vault Mirror","description":"Add bidirectional markdown mirror layer: Convex remains system of record, markdown vault provides human-inspectable Obsidian-compatible files.\n\n**Implementation order (dependency chain):**\nP1 Core: engram-ywx (schema) → engram-waf (format) → engram-7yr (sync engine) → engram-dxj (MCP tool)\nP1 Parallel: engram-ri0 (Convex actions, depends on ywx)\nP2 Enhancements: engram-doo (observation pipeline), engram-43e (graph+autolinker), engram-gxr (index pipeline), engram-vj6 (query tools), engram-ykh (backlinks), engram-4ul (checkpoint/wake), engram-sll (budgeted recall)\nP3 Advanced: engram-uah (file watcher), engram-8nz (auditability)\nP4 Quality: engram-0ro (validation suite)\n\n**Key corrections applied (2026-02-14):**\n- Flattened observation.* fields to observationTier/observationCompressed/observationOriginalContent (Convex compatibility)\n- Fixed index references: timestamp (not createdAt), lifecycleState (not status)\n- Added missing spec fields: confidence, importanceTier\n- Clarified ri0 vs 8nz layer boundaries (Convex actions vs MCP lib)\n\nSee specs/obsidian-mirror-plan.md and specs/clawvault-learnings.md for full details.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-14T22:55:59.277332+01:00","updated_at":"2026-02-14T23:26:02.615802+01:00","closed_at":"2026-02-14T23:26:02.615802+01:00","close_reason":"Closed"}
{"id":"engram-2vw","title":"Embedding Subspace Consolidation via SVD","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:14.240074+01:00","updated_at":"2026-02-24T09:33:14.240074+01:00"}
{"id":"engram-34c","title":"Implement event polling tool","description":"Create memory_poll_events MCP tool with watermark-based pagination. Add Convex query for pollByAgent with efficient indexing","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:39.654975+01:00","updated_at":"2026-02-15T00:58:49.27364+01:00","closed_at":"2026-02-15T00:58:49.27364+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-34c","depends_on_id":"engram-qcu","type":"blocks","created_at":"2026-02-15T00:39:12.095126+01:00","created_by":"daemon"}]}
{"id":"engram-3sg","title":"Security hardening implementation pass","description":"Implement remaining security tasks from plan: strong input length/format validation, structured error boundaries, optional API key guard, ENGRAM_AGENT_ID verification against registered agent, admin operation audit logging, and per-agent rate limiting. Ensure no stack traces leak to MCP clients and add boundary/injection tests.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:56.744334+01:00","updated_at":"2026-02-15T00:50:22.628385+01:00","closed_at":"2026-02-15T00:50:22.628385+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-3sg","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:08.68395+01:00","created_by":"daemon"}]}
{"id":"engram-43e","title":"Knowledge graph index + auto-linker for wiki-links","description":"Knowledge graph index + wiki-link auto-linking:\n\n**New files:**\n1. mcp-server/src/lib/wiki-link-parser.ts:\n   - extractWikiLinks(content) → WikiLink[] — Parse [[Name]] links, return {name, startIndex, endIndex}\n   - hasWikiLink(content, entityName) → boolean — Check if entity already linked\n   - Edge cases: nested brackets (parse outer), escaped \\[[...]] (ignore), whitespace [[  Name  ]] (trim)\n\n2. mcp-server/src/lib/auto-linker.ts:\n   - autoLinkEntities(content, scopeId, convex) → string — Auto-wrap entity mentions in [[...]]\n   - Algorithm: (1) Get all entities in scope, (2) Extract existing links, (3) Sort entities by name length (longest first), (4) Replace first mention of each entity with [[Name]], (5) Skip if already linked\n   - Case-insensitive matching, word boundaries only (\\b...\\b)\n\n3. mcp-server/src/lib/graph-exporter.ts:\n   - exportGraph(convex, outputPath) → void — Generate Obsidian-compatible graph JSON\n   - Format: {nodes: [{id, label, type, group}], links: [{source, target, type}]}\n   - Include fact→entity edges (type: 'mentions') and entity→entity edges (type: rel.relationshipType)\n\n**Convex schema changes (entities table):**\n- Add backlinks array: v.array(v.object({factId: v.id('facts'), factType: v.string(), linkedAt: v.number()}))\n\n**Integration in store-fact.ts:**\n- Before storing: linkedContent = await autoLinkEntities(content, scopeId, convex)\n- After storing: Update entity backlinks for each [[Name]] found\n\n**New MCP tool (in engram-vj6):**\n- memory_export_graph — Export graph to vault/.obsidian/graph.json\n\n**Tests:** auto-linking-e2e.test.ts (store fact mentioning 'Convex' → content has [[Convex]]), graph-export-e2e.test.ts (valid Obsidian JSON)\n**Performance:** Auto-link \u003c50ms, graph export \u003c2s for 10k facts\nRef: VAULT_INTEGRATION_PLAN.md Phase 4 (sections 4.2-4.6)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:39.209329+01:00","updated_at":"2026-02-14T23:24:51.499865+01:00","closed_at":"2026-02-14T23:24:51.499865+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-43e","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T22:57:20.586856+01:00","created_by":"daemon"}]}
{"id":"engram-46g","title":"Install vault integration npm dependencies","description":"Install required npm packages for vault integration:\n\n**MCP server dependencies:**\n```bash\ncd mcp-server\nbun add chokidar js-yaml marked slugify\nbun add -d @types/js-yaml @types/marked\n```\n\n**Packages:**\n- chokidar ^4.0.1 — File watching for vault-sync daemon\n- js-yaml ^4.1.0 — YAML frontmatter parsing\n- marked ^15.0.4 — Markdown parsing (if needed)\n- slugify ^1.6.6 — Filename slug generation\n- @types/js-yaml ^4.0.9 — TypeScript types\n- @types/marked ^7.0.0 — TypeScript types\n\n**Verification:**\n- Run bun install to ensure lock file updated\n- Verify imports work: import yaml from 'js-yaml', import chokidar from 'chokidar'\n- No version conflicts with existing packages\n\n**This blocks:** engram-waf (needs slugify + js-yaml), engram-7yr (needs chokidar)\n\nRef: VAULT_INTEGRATION_PLAN.md Appendix B","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T23:07:22.072674+01:00","updated_at":"2026-02-14T23:24:06.553393+01:00","closed_at":"2026-02-14T23:24:06.553393+01:00","close_reason":"Closed"}
{"id":"engram-46p","title":"Refactor enrichment to use config resolver","description":"Update convex/actions/importance.ts, convex/crons/decay.ts, convex/crons/forget.ts, mcp-server/src/lib/ranking.ts to call resolveConfig instead of hardcoded constants","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:28.997364+01:00","updated_at":"2026-02-15T00:50:22.520377+01:00","closed_at":"2026-02-15T00:50:22.520377+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-46p","depends_on_id":"engram-jsf","type":"blocks","created_at":"2026-02-15T00:38:56.817255+01:00","created_by":"daemon"}]}
{"id":"engram-4k3","title":"Active Forgetting Pipeline (ALMA)","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:13.55217+01:00","updated_at":"2026-02-24T09:33:13.55217+01:00"}
{"id":"engram-4rr","title":"Finish primitive decomposition for recall/context workflows","description":"Add missing primitive tools required by plan decomposition: memory_vector_search, memory_text_search, memory_bump_access, memory_record_recall, memory_get_observations, memory_get_entities, memory_get_themes, memory_get_handoffs, memory_get_notifications, memory_mark_notifications_read. Keep memory_recall and memory_get_context as orchestration wrappers for backwards compatibility. Add contract tests to verify wrappers are equivalent to primitive composition.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:55.017797+01:00","updated_at":"2026-02-15T00:47:31.140075+01:00","closed_at":"2026-02-15T00:47:31.140075+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-4rr","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:07.491423+01:00","created_by":"daemon"}]}
{"id":"engram-4ul","title":"Checkpoint/wake tools for context death resilience","description":"Add two new MCP tools for session continuity across context deaths:\n\n(1) memory_checkpoint: params workingOn (string), focus (optional), blocked (optional), urgent (bool). Writes to .engram/last-checkpoint.json + checkpoint history. Sets dirty-death flag. If urgent, triggers immediate wake.\n\n(2) memory_wake: detects dirty-death flag, loads checkpoint data, loads recent observations with temporal decay (today=all structural+potential, yesterday=structural+top5 potential, 2-3 days=structural only, 4-6 days=top 3 structural), builds session recap from handoffs/projects/commitments, returns bootstrap context.\n\n(3) memory_end_session should clear the dirty-death flag on clean exit.\n\nRequires observationTier field from engram-ywx (via engram-doo classification) to filter by importance tier during wake context loading.\n\nRef: specs/obsidian-mirror-plan.md §6.1-6.3, ClawVault checkpoint.ts + wake.ts pattern","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:57.086118+01:00","updated_at":"2026-02-14T23:25:41.793376+01:00","closed_at":"2026-02-14T23:25:41.793376+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-4ul","depends_on_id":"engram-doo","type":"blocks","created_at":"2026-02-14T22:57:23.00886+01:00","created_by":"daemon"}]}
{"id":"engram-5v2","title":"Deployment verification automation and evidence artifacts","description":"Translate DEPLOYMENT-VERIFICATION-CHECKLIST.md into executable or scriptable checks where possible: pre/post record-count verification, schema verification, tool count verification, and invariant validation helpers. Produce machine-runnable checks plus a concise evidence report format for go/no-go decisions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:58.061194+01:00","updated_at":"2026-02-15T00:49:13.005283+01:00","closed_at":"2026-02-15T00:49:13.005283+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-5v2","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:10.716927+01:00","created_by":"daemon"},{"issue_id":"engram-5v2","depends_on_id":"engram-hx4","type":"blocks","created_at":"2026-02-15T00:34:11.124424+01:00","created_by":"daemon"}]}
{"id":"engram-5y2","title":"Seed and manage runtime config values","description":"Create and validate seed path for extracting hardcoded values to database-backed config. Include seedSystemConfig plus resolver tests and admin-facing primitives for get/set/list config and set scope policy. Must include rollback-safe versioning/update metadata and acceptance checks that existing behavior remains unchanged when config rows are absent.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:53.315767+01:00","updated_at":"2026-02-15T00:47:31.137318+01:00","closed_at":"2026-02-15T00:47:31.137318+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-5y2","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:06.003235+01:00","created_by":"daemon"}]}
{"id":"engram-6fx","title":"Staging rehearsal, rollback drill, and release readiness gate","description":"Create a release-readiness bead that captures staging deployment, rollback rehearsal, on-call checklist validation, and sign-off artifacts. Include explicit pass/fail criteria mapped to deployment checklist rows and final GO/NO-GO recording procedure.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T00:33:59.477669+01:00","updated_at":"2026-02-15T00:58:48.52275+01:00","closed_at":"2026-02-15T00:58:48.52275+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-6fx","depends_on_id":"engram-5v2","type":"blocks","created_at":"2026-02-15T00:34:13.102491+01:00","created_by":"daemon"},{"issue_id":"engram-6fx","depends_on_id":"engram-9q5","type":"blocks","created_at":"2026-02-15T00:34:13.490513+01:00","created_by":"daemon"}]}
{"id":"engram-6v6","title":"Add DELETE mutations for 7 entities","description":"Implement deleteEntity, deleteScope, deleteConversation, deleteSession, deleteTheme mutations in Convex. Soft delete via lifecycleState='archived' or hard delete with cascade options","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:27.085241+01:00","updated_at":"2026-02-15T00:45:34.332474+01:00","closed_at":"2026-02-15T00:45:34.332474+01:00","close_reason":"Closed"}
{"id":"engram-7yr","title":"Create vault-sync.ts: Convex→MD export engine","description":"Create mcp-server/src/lib/vault-writer.ts + mcp-server/src/daemons/vault-sync.ts:\n\n**vault-writer.ts:**\n- writeFactToVault(fact, vaultRoot) — Generate frontmatter + body, compute folder/filename, ensure folder exists (mkdir -p), atomic write (tempfile + rename), return {success, path, error}\n- Error handling: disk full (retry w/ backoff), permission denied (log + mark unmirrored), invalid filename (sanitize + retry)\n- Performance: \u003c500ms p95 for write\n\n**vault-sync daemon (daemons/vault-sync.ts):**\n- Poll Convex every 5s for facts with vaultPath==null (getUnmirrored query, limit 100)\n- Write files using vault-writer.ts\n- Update fact.vaultPath + vaultSyncedAt in Convex after success\n- Watch vault/ using chokidar for file changes (ignoreInitial: true)\n- On file change: trigger reconcileFromVault action (to be implemented in engram-8nz)\n- Graceful shutdown on SIGTERM/SIGINT\n- Exponential backoff on Convex connection errors\n- Logging: JSON structured logs with event, factId, latency, timestamp\n\n**Lifecycle:**\n- Starts with MCP server (bun run mcp-server/src/index.ts)\n- Restarts automatically on crash\n\n**Dependencies:** chokidar, ConvexHttpClient\n**Tests:** write-through-e2e.test.ts (store fact → file appears \u003c5s), high-volume-writes.test.ts (10k facts in 60s)\n**Performance:** Mirror lag \u003c5s p95, sync reliability 99.99%\nRef: VAULT_INTEGRATION_PLAN.md Phase 3 (sections 3.1-3.3, 3.5-3.7)","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:18.15318+01:00","updated_at":"2026-02-14T23:24:13.000427+01:00","closed_at":"2026-02-14T23:24:13.000427+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-7yr","depends_on_id":"engram-waf","type":"blocks","created_at":"2026-02-14T22:57:18.458469+01:00","created_by":"daemon"},{"issue_id":"engram-7yr","depends_on_id":"engram-46g","type":"blocks","created_at":"2026-02-14T23:07:29.701337+01:00","created_by":"daemon"}]}
{"id":"engram-7zs","title":"Production docs overhaul for v2 architecture","description":"Create/update docs required by plan: USAGE-EXAMPLES.md (\u003e=10 scenarios), API-REFERENCE.md (all tools), INSTALLATION.md, CONFIGURATION.md, TROUBLESHOOTING.md, and README quick-start refresh. Ensure docs are operationally accurate against live code and include deployment verification references.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T00:33:57.627603+01:00","updated_at":"2026-02-15T00:49:13.002132+01:00","closed_at":"2026-02-15T00:49:13.002132+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-7zs","depends_on_id":"engram-1wl","type":"blocks","created_at":"2026-02-15T00:34:09.897525+01:00","created_by":"daemon"},{"issue_id":"engram-7zs","depends_on_id":"engram-4rr","type":"blocks","created_at":"2026-02-15T00:34:10.308605+01:00","created_by":"daemon"}]}
{"id":"engram-8nz","title":"Auditability: diffs, provenance metadata, edit reconciliation","description":"MCP-side auditability layer: reconciliation lib, diffs, provenance metadata. This is the MCP lib layer; the Convex-side reconciliation action is in engram-ri0.\n\n**New file: mcp-server/src/lib/vault-reconciler.ts**\n\n1. reconcileFileEdit(filePath, convex):\n   - Read file from disk, parse frontmatter + body\n   - Fetch DB fact by convexId from frontmatter\n   - Compare updatedAt timestamps\n   - If DB newer: check for conflicts using detectConflicts()\n   - Merge human edits using mergeHumanEdits()\n   - Call Convex reconcileFromVault action (engram-ri0) with merged data\n   - Return {success, conflicts[]}\n\n2. detectConflicts(dbFact, fileFact) returns ConflictField[]:\n   - Check HUMAN_EDITABLE_FIELDS for divergent changes\n   - Return array of {field, dbValue, fileValue}\n\n3. writeConflictFile(filePath, dbFact, fileFact, conflicts):\n   - Create {filename}.conflict.md in vault/.meta/conflicts/\n   - Show both values side-by-side with resolution instructions\n\n**Provenance tracking:**\n- All markdown files include provenance footer: agent, timestamp, accessedCount, sessionId\n- Frontmatter includes: source (session/import/migration), sessionId\n\n**New MCP tool: memory_vault_diff**\n- Show pending changes between vault and Convex before sync\n\n**Tests:** reconcile-e2e.test.ts, conflict-e2e.test.ts, roundtrip.test.ts\n**Performance:** Reconcile \u003c200ms p95, zero data loss over 10k ops\nRef: specs/obsidian-mirror-plan.md §2.4","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-14T22:57:07.001323+01:00","updated_at":"2026-02-14T23:25:41.908183+01:00","closed_at":"2026-02-14T23:25:41.908183+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-8nz","depends_on_id":"engram-waf","type":"blocks","created_at":"2026-02-14T23:08:15.003764+01:00","created_by":"daemon"},{"issue_id":"engram-8nz","depends_on_id":"engram-ri0","type":"blocks","created_at":"2026-02-14T23:08:15.449398+01:00","created_by":"daemon"}]}
{"id":"engram-8ro","title":"Phase 5: Local Sync — LanceDB daemon, offline vector search fallback","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T10:02:08.462183+01:00","updated_at":"2026-02-12T10:06:05.733398+01:00","closed_at":"2026-02-12T10:06:05.733398+01:00","close_reason":"Completed"}
{"id":"engram-95y","title":"Decompose memory_get_context into primitives","description":"Create 6+ tools: memory_search_facts, memory_search_entities, memory_search_themes, memory_get_handoffs, memory_get_notifications, memory_mark_notifications_read","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:32.517933+01:00","updated_at":"2026-02-15T00:58:47.763739+01:00","closed_at":"2026-02-15T00:58:47.763739+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-95y","depends_on_id":"engram-ai3","type":"blocks","created_at":"2026-02-15T00:39:05.193828+01:00","created_by":"daemon"}]}
{"id":"engram-9q5","title":"Comprehensive test expansion: unit, e2e, security, performance","description":"Add full coverage requested by plan: primitive tool unit tests, orchestration wrapper equivalence tests, cross-agent coordination E2E, scope-isolation security tests, and performance/load harness checks. Ensure detailed logging and deterministic assertions for CI use.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:58.990264+01:00","updated_at":"2026-02-15T00:51:19.863974+01:00","closed_at":"2026-02-15T00:51:19.863974+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-9q5","depends_on_id":"engram-4rr","type":"blocks","created_at":"2026-02-15T00:34:11.945326+01:00","created_by":"daemon"},{"issue_id":"engram-9q5","depends_on_id":"engram-djs","type":"blocks","created_at":"2026-02-15T00:34:12.335615+01:00","created_by":"daemon"},{"issue_id":"engram-9q5","depends_on_id":"engram-3sg","type":"blocks","created_at":"2026-02-15T00:34:12.725508+01:00","created_by":"daemon"}]}
{"id":"engram-ai3","title":"Phase 1: Configuration Foundation","description":"Extract hardcoded configs to database tables (system_config, memory_policies). Implement config resolver with priority: scope policy \u003e system config \u003e fallback. Add DELETE operations for 7 entities. Migration script to seed extracted constants.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-15T00:38:07.052306+01:00","updated_at":"2026-02-15T00:51:19.879705+01:00","closed_at":"2026-02-15T00:51:19.879705+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-ai3","depends_on_id":"engram-26p","type":"blocks","created_at":"2026-02-15T00:38:57.246827+01:00","created_by":"daemon"},{"issue_id":"engram-ai3","depends_on_id":"engram-17d","type":"blocks","created_at":"2026-02-15T00:38:57.639198+01:00","created_by":"daemon"},{"issue_id":"engram-ai3","depends_on_id":"engram-jsf","type":"blocks","created_at":"2026-02-15T00:38:58.041626+01:00","created_by":"daemon"},{"issue_id":"engram-ai3","depends_on_id":"engram-6v6","type":"blocks","created_at":"2026-02-15T00:38:58.413548+01:00","created_by":"daemon"},{"issue_id":"engram-ai3","depends_on_id":"engram-46p","type":"blocks","created_at":"2026-02-15T00:38:59.022649+01:00","created_by":"daemon"}]}
{"id":"engram-ajw","title":"Emotional Weight in Ranking","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:13.795435+01:00","updated_at":"2026-02-24T09:33:13.795435+01:00"}
{"id":"engram-c48","title":"Phase 2: Tool Primitization","description":"Decompose 11 workflow tools into 25+ atomic primitives. Implement primitives with Convex string-based paths pattern. Add backwards compatibility wrappers. Update MCP tool registry.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-15T00:38:08.383267+01:00","updated_at":"2026-02-15T00:58:50.840153+01:00","closed_at":"2026-02-15T00:58:50.840153+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-c48","depends_on_id":"engram-dt4","type":"blocks","created_at":"2026-02-15T00:39:07.580672+01:00","created_by":"daemon"},{"issue_id":"engram-c48","depends_on_id":"engram-95y","type":"blocks","created_at":"2026-02-15T00:39:08.294758+01:00","created_by":"daemon"},{"issue_id":"engram-c48","depends_on_id":"engram-vgb","type":"blocks","created_at":"2026-02-15T00:39:08.909016+01:00","created_by":"daemon"},{"issue_id":"engram-c48","depends_on_id":"engram-1vx","type":"blocks","created_at":"2026-02-15T00:39:09.355218+01:00","created_by":"daemon"}]}
{"id":"engram-djs","title":"Close CRUD parity gaps for entity/scope/conversation/session and fact operations","description":"Implement remaining action parity tools/mutations listed in plan: deleteEntity, deleteScope (with safe cascade/prevent rules), deleteConversation, deleteSession, updateFact, archiveFact, boostRelevance, createTheme plus MCP wrappers. Enforce scope authorization checks uniformly and add negative tests for unauthorized operations.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:55.801891+01:00","updated_at":"2026-02-15T00:45:34.510579+01:00","closed_at":"2026-02-15T00:45:34.510579+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-djs","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:07.911001+01:00","created_by":"daemon"}]}
{"id":"engram-doo","title":"Observation pipeline: scored format + importance tiers","description":"Priority-tiered observation pipeline with LLM classification:\n\n**New Convex actions:**\n1. convex/actions/classifyObservation.ts:\n   - Use Claude Haiku for fast classification (\u003c2s)\n   - Prompt: Classify into CRITICAL (decisions/commitments/failures), NOTABLE (insights/learnings), BACKGROUND (routine/minor)\n   - Map tier to priority: CRITICAL→0, NOTABLE→1, BACKGROUND→4\n   - Update fact with priority + observationTier (flat field, see engram-ywx)\n   - If P0-P2: Trigger full enrichment (embeddings, entities, importance)\n   - If P3-P4: Trigger background compression\n\n2. convex/actions/compressBackground.ts:\n   - Generate 1-sentence summary (max 20 words) using Haiku\n   - Store original in observationOriginalContent (flat field)\n   - Set observationCompressed = true (flat field)\n   - Set lifecycleState = \"archived\" (skip indexing/recall)\n\n**MCP tool change (mcp-server/src/tools/observe.ts):**\n- Store observation with lifecycleState=\"active\", trigger classifyObservation action (non-blocking)\n- Agent gets immediate response, classification happens async\n\n**Recall filtering (mcp-server/src/tools/recall.ts):**\n- Add priority filter: default exclude P3-P4 unless explicit priorityFilter arg\n\n**Schema fields (in engram-ywx):**\n- observationTier: v.optional(v.string()) — \"critical\"|\"notable\"|\"background\"\n- observationCompressed: v.optional(v.boolean())\n- observationOriginalContent: v.optional(v.string()) — Content before compression\n\nNOTE: All observation.* fields from original plan are flattened for Convex compatibility.\n\n**Tests:** observation-compression-e2e.test.ts, classification-latency.test.ts (\u003c2s)\n**Performance:** Classification \u003c2s, compression \u003c1s, observation noise reduction \u003e80%\nRef: specs/obsidian-mirror-plan.md §3.1-3.3","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:32.190346+01:00","updated_at":"2026-02-14T23:25:03.926873+01:00","closed_at":"2026-02-14T23:25:03.926873+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-doo","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T22:57:19.817066+01:00","created_by":"daemon"}]}
{"id":"engram-dt4","title":"Decompose memory_recall into primitives","description":"Create 4 new tools: memory_vector_search, memory_text_search, memory_bump_access, memory_record_recall. Update mcp-server/src/tools/ and add Convex functions with string-based paths","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:30.78059+01:00","updated_at":"2026-02-15T00:58:47.40422+01:00","closed_at":"2026-02-15T00:58:47.40422+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-dt4","depends_on_id":"engram-ai3","type":"blocks","created_at":"2026-02-15T00:39:04.458429+01:00","created_by":"daemon"}]}
{"id":"engram-dxj","title":"Add MCP tool: memory_vault_sync","description":"Add MCP tool: memory_vault_sync for manual vault synchronization:\n\n**New tool: memory_vault_sync (mcp-server/src/tools/vault-sync.ts)**\n\nParameters:\n- direction: 'export' | 'import' | 'both' (default: 'both')\n- force: boolean (default: false) — Force re-export even if vaultPath exists\n- dryRun: boolean (default: false) — Show what would be synced without executing\n\n**Export mode (Convex → Vault):**\n- Fetch all facts with vaultPath == null OR force == true\n- Export to markdown using vault-format.ts\n- Update vaultPath + vaultSyncedAt in Convex\n- Return: {exported: count, skipped: count, errors: []}\n\n**Import mode (Vault → Convex):**\n- Scan vault/ for .md files\n- Parse frontmatter, match by ID\n- Reconcile changes using vault-reconciler.ts\n- Update DB with human edits\n- Return: {imported: count, conflicts: count, errors: []}\n\n**Both mode:**\n- Run export first, then import\n- Return combined stats\n\n**Use cases:**\n- Initial vault population after system install\n- Manual sync after vault-sync daemon crashes\n- Batch import after human edits in Obsidian\n- Dry run to preview sync changes\n\n**Integration:**\n- Uses vault-writer.ts (from engram-7yr)\n- Uses vault-reconciler.ts (from engram-8nz)\n- Uses vault-format.ts (from engram-waf)\n\n**Tests:** vault-sync-e2e.test.ts (export/import/both modes work), dry-run.test.ts (no actual changes)\n**Performance:** Export 1000 facts \u003c10s, import 1000 files \u003c15s\nRef: VAULT_INTEGRATION_PLAN.md Phase 3.2, Phase 3.4","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:26.618882+01:00","updated_at":"2026-02-14T23:24:31.181896+01:00","closed_at":"2026-02-14T23:24:31.181896+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-dxj","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T22:57:19.207572+01:00","created_by":"daemon"}]}
{"id":"engram-gxr","title":"Vault index pipeline implementation + cron trigger","description":"Vault index pipeline for index-first retrieval:\n\n**New file: mcp-server/src/lib/vault-indexer.ts**\nImplements index generation:\n\n1. generateIndices(convex, vaultRoot) — Master function, creates:\n   - vault/.index/vault-index.md — Master TOC (recent + by-type sections)\n   - vault/.index/by-priority.md — Facts grouped by priority tier (0-4)\n   - vault/.index/by-entity.md — Facts grouped by entity mentions\n\n2. generateMasterIndex(facts, vaultRoot):\n   - Recent section: Last 7 days, sorted by date desc\n   - By Type section: Group by fact.type, sort by importance desc, show top 10 per type\n   - Format: '- [date] **Type**: title → path [importance: X.XX]'\n\n3. generatePriorityIndex(facts, vaultRoot):\n   - 5 sections: Critical (P0), High (P1), Medium (P2), Low (P3), Backlog (P4)\n   - Sort within tier by importance desc, show top 20 per tier\n\n4. generateEntityIndex(facts, vaultRoot):\n   - Build mention count map from wiki-links\n   - Sort entities by mention count desc\n   - For each entity: show top 10 facts by importance\n\n**Recall tool enhancement (mcp-server/src/tools/recall.ts):**\n- searchIndex(query, filters) — Scan relevant index file, extract matching paths, compute confidence\n- Index-first strategy: If 5+ matches AND confidence \u003e0.7 → return index results, else fallback to semantic\n- Confidence = (keyword coverage) × (match density)\n\n**Convex cron (convex/crons/regenerateIndices.ts):**\n- Schedule: */5 * * * * (every 5 minutes)\n- Action: Signal MCP daemon to regenerate indices (webhook or polling flag)\n\n**Tests:** index-generation.test.ts (verify format), index-first-e2e.test.ts (query → index scan → results)\n**Performance:** Index scan \u003c100ms p95, index hit rate \u003e65%, relevance@5 \u003e0.85\nRef: VAULT_INTEGRATION_PLAN.md Phase 5 (sections 5.2-5.7)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:26.85327+01:00","updated_at":"2026-02-14T23:25:26.47989+01:00","closed_at":"2026-02-14T23:25:26.47989+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-gxr","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T23:01:38.333371+01:00","created_by":"daemon"},{"issue_id":"engram-gxr","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:44.162538+01:00","created_by":"daemon"}]}
{"id":"engram-h09","title":"Phase 3: Async Enrichment — Cohere Embed 4, entity extraction, synthesis, importance","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:50:59.367012+01:00","updated_at":"2026-02-12T10:06:05.440978+01:00","closed_at":"2026-02-12T10:06:05.440978+01:00","close_reason":"Completed"}
{"id":"engram-hgc","title":"Implement multi-source context gathering in memory_get_context","description":"Complete remaining UNIMPLEMENTED.md item: gather observations by tier plus daily notes/search results/graph-neighbor expansion in get-context.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T23:53:27.166421+01:00","updated_at":"2026-02-14T23:54:17.055783+01:00","closed_at":"2026-02-14T23:54:17.055783+01:00","close_reason":"Closed"}
{"id":"engram-hna","title":"Agent-native production refactor plan execution","description":"Execute docs/plans/2026-02-14-refactor-agent-native-architecture-production-ready-plan.md and docs/plans/DEPLOYMENT-VERIFICATION-CHECKLIST.md end-to-end as a dependency-driven bead graph. This epic tracks conversion of remaining plan items into production-ready deliverables: schema/config foundations, primitive tool decomposition, action parity gaps, event propagation, security/performance hardening, docs overhaul, and deployment verification artifacts. Every child bead must be self-contained and include explicit validation outcomes so implementation can run without re-opening the source plan docs.","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-15T00:33:52.444203+01:00","updated_at":"2026-02-15T00:39:31.911421+01:00","closed_at":"2026-02-15T00:39:31.911421+01:00","close_reason":"Superseded by engram-ai3, engram-c48, engram-1le (new phase epics with detailed tasks)"}
{"id":"engram-hx4","title":"Implement memory_events propagation and poll primitive","description":"Emit memory_events for storeFact, enrichment completion, and notification creation. Add memory_poll_events tool with watermark-based polling semantics and pagination. Document client polling loop and latency targets (\u003c5s end-to-end propagation). Include event ordering/idempotency tests.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:56.286293+01:00","updated_at":"2026-02-15T00:45:34.509931+01:00","closed_at":"2026-02-15T00:45:34.509931+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-hx4","depends_on_id":"engram-wii","type":"blocks","created_at":"2026-02-15T00:34:08.292966+01:00","created_by":"daemon"}]}
{"id":"engram-jsf","title":"Create config migration script","description":"Build convex/migrations/001_seed_system_config.ts to extract all hardcoded constants from importance.ts, decay.ts, forget.ts, ranking.ts and seed into system_config table","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:25.098786+01:00","updated_at":"2026-02-15T00:49:13.01154+01:00","closed_at":"2026-02-15T00:49:13.01154+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-jsf","depends_on_id":"engram-17d","type":"blocks","created_at":"2026-02-15T00:38:56.468795+01:00","created_by":"daemon"}]}
{"id":"engram-naa","title":"KV Store for Deterministic Facts","description":"# KV Store for Deterministic Facts\n\n## Problem\nEngram's current recall uses hybrid text+vector search for all queries. This creates false negatives for **explicit, deterministic facts** like preferences, rules, and configuration data. For example:\n- \"Ryan prefers Bun over npm\" should ALWAYS be recalled when querying about package managers\n- Vector similarity might miss this if embeddings drift or query phrasing changes\n- Sub-5ms deterministic recall is impossible with vector search\n\n## Solution (from Mem0)\nAdd a **key_value_facts** table for exact-match retrieval of deterministic facts. Three-store architecture:\n1. **KV store**: Deterministic facts (preferences, rules, profile data)\n2. **Vector store**: Semantic/fuzzy search (current implementation)\n3. **Graph store**: Relationship traversal (current entities table)\n\n## Schema Changes\n```typescript\n// Add to convex/schema.ts\nkey_value_facts: defineTable({\n  key: v.string(),           // normalized: \"ryan.preference.package_manager\"\n  value: v.string(),         // \"bun\"\n  factId: v.id(\"facts\"),   // backlink to full fact for provenance\n  scopeId: v.id(\"memory_scopes\"),\n  agentId: v.string(),\n  updatedAt: v.number(),\n  metadata: v.optional(v.record(v.string(), metadataValue)), // extensible\n}).index(\"by_key\", [\"key\"])\n  .index(\"by_scope\", [\"scopeId\"])\n  .index(\"by_scope_key\", [\"scopeId\", \"key\"])\n```\n\n## Auto-Classification Logic\nWhen `store_fact` is called, auto-detect deterministic facts:\n- Patterns: \"prefers\", \"always\", \"never\", \"rule:\", \"default is\"\n- Store in BOTH facts table AND key_value_facts\n- Key generation: entity-based (\"ryan.preference.X\") or topic-based (\"project.briefly.build_tool\")\n\n## Recall Flow Changes\n```typescript\n// In recall.ts, add KV lookup BEFORE vector/text search:\n1. Extract entities/keywords from query\n2. Generate potential KV keys\n3. Check key_value_facts for exact matches (\u003c 5ms)\n4. If found: boost these facts to top of results\n5. Fall through to hybrid vector/text for remaining slots\n```\n\n## Impact\n- Eliminates false negatives on explicit preferences/rules\n- Sub-5ms for deterministic recalls (vs 50-200ms for vector)\n- Reduces vector DB load for simple lookups\n- Enables strict policy enforcement (\"always do X\", \"never do Y\")\n\n## References\n- Mem0 architecture: three-store pattern (KV + vector + graph)\n- Current schema: convex/schema.ts (lines 1-100)\n- Current recall: mcp-server/src/tools/recall.ts\n- Optimization doc: docs/OPTIMIZATION-2026-02-24.md (section 1)","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-24T09:33:12.627165+01:00","updated_at":"2026-02-24T09:33:41.243024+01:00"}
{"id":"engram-naa.1","title":"Schema: Add key_value_facts table","description":"Add `key_value_facts` table to `convex/schema.ts` for deterministic fact storage.\n\n**Location**: `convex/schema.ts` (after line 300, before sync_log)\n\n**Schema Definition**:\n```typescript\nkey_value_facts: defineTable({\n  key: v.string(),           // normalized key (e.g., \"ryan.preference.package_manager\")\n  value: v.string(),         // stringified value (\"bun\")\n  factId: v.id(\"facts\"),   // backlink to source fact for full context/provenance\n  scopeId: v.id(\"memory_scopes\"),\n  agentId: v.string(),       // agent that stored this KV\n  updatedAt: v.number(),     // timestamp for cache invalidation\n  metadata: v.optional(v.record(v.string(), metadataValue)), // extensible metadata\n}).index(\"by_key\", [\"key\"])\n  .index(\"by_scope\", [\"scopeId\"])\n  .index(\"by_scope_key\", [\"scopeId\", \"key\"])  // composite for scoped lookups\n  .index(\"by_fact\", [\"factId\"])               // reverse lookup\n```\n\n**Key Generation Rules**:\n- Entity-based: `{entity}.{category}.{attribute}` (e.g., \"ryan.preference.editor\")\n- Project-based: `project.{name}.{setting}` (e.g., \"project.engram.build_tool\")\n- Global: `global.{category}.{key}` (e.g., \"global.policy.max_tokens\")\n\n**Migration**: None needed (new table, no existing data).\n\n**Validation**: Ensure indices are created correctly, test query performance with `convex dev`.","status":"open","priority":0,"issue_type":"task","created_at":"2026-02-24T09:33:48.968628+01:00","updated_at":"2026-02-24T09:34:15.560339+01:00","dependencies":[{"issue_id":"engram-naa.1","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:48.973985+01:00","created_by":"daemon"}]}
{"id":"engram-naa.2","title":"Convex: Implement kv-store.ts mutations","description":"Create `convex/kv-store.ts` with mutations for key-value fact management.\n\n**File**: `convex/kv-store.ts` (new file)\n\n**Exports**:\n1. `setKV(ctx, { key, value, factId, scopeId, agentId })` — Insert or update KV fact\n2. `getKV(ctx, { key, scopeId? })` — Query by exact key, optionally scoped\n3. `deleteKV(ctx, { key, scopeId })` — Remove KV fact\n4. `listKVByScope(ctx, { scopeId, limit? })` — List all KV facts in scope\n5. `batchSetKV(ctx, { entries: Array\u003c{key, value, factId, scopeId, agentId}\u003e })` — Bulk insert\n\n**Implementation Details**:\n```typescript\nimport { mutation, query } from \"./_generated/server\";\nimport { v } from \"convex/values\";\n\nexport const setKV = mutation({\n  args: {\n    key: v.string(),\n    value: v.string(),\n    factId: v.id(\"facts\"),\n    scopeId: v.id(\"memory_scopes\"),\n    agentId: v.string(),\n  },\n  handler: async (ctx, args) =\u003e {\n    // Check if key exists in scope\n    const existing = await ctx.db\n      .query(\"key_value_facts\")\n      .withIndex(\"by_scope_key\", (q) =\u003e q.eq(\"scopeId\", args.scopeId).eq(\"key\", args.key))\n      .unique();\n\n    if (existing) {\n      // Update existing\n      await ctx.db.patch(existing._id, {\n        value: args.value,\n        factId: args.factId,\n        updatedAt: Date.now(),\n      });\n      return { kvId: existing._id, updated: true };\n    } else {\n      // Insert new\n      const kvId = await ctx.db.insert(\"key_value_facts\", {\n        ...args,\n        updatedAt: Date.now(),\n      });\n      return { kvId, updated: false };\n    }\n  },\n});\n\nexport const getKV = query({\n  args: { key: v.string(), scopeId: v.optional(v.id(\"memory_scopes\")) },\n  handler: async (ctx, args) =\u003e {\n    if (args.scopeId) {\n      return await ctx.db\n        .query(\"key_value_facts\")\n        .withIndex(\"by_scope_key\", (q) =\u003e q.eq(\"scopeId\", args.scopeId).eq(\"key\", args.key))\n        .unique();\n    } else {\n      return await ctx.db\n        .query(\"key_value_facts\")\n        .withIndex(\"by_key\", (q) =\u003e q.eq(\"key\", args.key))\n        .first();\n    }\n  },\n});\n```\n\n**Error Handling**: Return `null` for missing keys (not an error), throw on invalid scopeId.\n\n**Testing**: Test upsert logic, scoped vs global queries, batch inserts.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:49.276633+01:00","updated_at":"2026-02-24T09:34:15.810894+01:00","dependencies":[{"issue_id":"engram-naa.2","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:49.277482+01:00","created_by":"daemon"}]}
{"id":"engram-naa.3","title":"MCP Tool: Update store_fact with auto-classification","description":"Update `mcp-server/src/tools/store-fact.ts` to auto-classify and store deterministic facts in KV store.\n\n**File**: `mcp-server/src/tools/store-fact.ts`\n\n**Changes**:\n1. **Import KV mutations**: `import { internal } from \"@/convex/_generated/api\";`\n2. **Add classification function**:\n```typescript\nfunction isDeterministicFact(content: string): boolean {\n  const patterns = [\n    /\\b(prefers?|preference)\\b/i,\n    /\\b(always|never)\\b/i,\n    /\\brule:/i,\n    /\\bdefault (is|to)\\b/i,\n    /\\b(must|should) (always|never)\\b/i,\n    /\\bsetting:/i,\n  ];\n  return patterns.some(p =\u003e p.test(content));\n}\n\nfunction extractKVKey(content: string, entities: string[]): string | null {\n  // Simple heuristic: first entity + attribute from pattern\n  // Example: \"Ryan prefers Bun\" → entities=[\"ryan\"], content has \"prefers Bun\"\n  // Result: \"ryan.preference.package_manager\" (needs NLP in v2)\n  \n  if (entities.length === 0) return null;\n  const entity = entities[0].toLowerCase().replace(/\\s+/g, \"_\");\n  \n  // Extract category from keywords\n  if (/prefers?|preference/i.test(content)) {\n    // Simple extraction: match \"prefers X\" or \"preference for X\"\n    const match = content.match(/prefers?\\s+([\\w\\-]+)/i);\n    if (match) return `${entity}.preference.${match[1].toLowerCase()}`;\n  }\n  \n  if (/rule:/i.test(content)) {\n    const match = content.match(/rule:\\s*([\\w\\-]+)/i);\n    if (match) return `${entity}.rule.${match[1].toLowerCase()}`;\n  }\n  \n  return null; // Fall back to fact-only storage\n}\n```\n\n3. **After fact insertion, call KV store**:\n```typescript\n// After const factId = await ctx.runMutation(...)\nif (isDeterministicFact(content)) {\n  const kvKey = extractKVKey(content, entityIds);\n  if (kvKey) {\n    await ctx.runMutation(internal.kv.setKV, {\n      key: kvKey,\n      value: content, // Store full content; can compress in v2\n      factId,\n      scopeId: resolvedScopeId,\n      agentId,\n    });\n    console.log(`[store-fact] Auto-stored KV: ${kvKey}`);\n  }\n}\n```\n\n**Testing**: Store \"Ryan prefers Bun over npm\" and verify KV entry created with key \"ryan.preference.bun\".","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:49.572818+01:00","updated_at":"2026-02-24T09:34:45.54665+01:00","dependencies":[{"issue_id":"engram-naa.3","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:49.573598+01:00","created_by":"daemon"}]}
{"id":"engram-naa.4","title":"MCP Tool: Update recall with KV lookup","description":"Update `mcp-server/src/tools/recall.ts` to check KV store BEFORE vector/text search.\n\n**File**: `mcp-server/src/tools/recall.ts`\n\n**Changes**:\n1. **Import KV query**: `import { internal } from \"@/convex/_generated/api\";`\n2. **Add KV lookup function**:\n```typescript\nasync function kvLookup(\n  ctx: any,\n  query: string,\n  scopeIds: string[]\n): Promise\u003cany[]\u003e {\n  // Extract potential KV keys from query\n  // Example: \"what does ryan prefer for package manager\" → try \"ryan.preference.package_manager\"\n  const kvKeys = extractPotentialKeys(query);\n  const results = [];\n  \n  for (const key of kvKeys) {\n    for (const scopeId of scopeIds) {\n      const kv = await ctx.runQuery(internal.kv.getKV, { key, scopeId });\n      if (kv) {\n        // Fetch the full fact for return\n        const fact = await ctx.runQuery(internal.facts.get, { id: kv.factId });\n        if (fact) results.push({ ...fact, _kvMatch: true });\n      }\n    }\n  }\n  \n  return results;\n}\n\nfunction extractPotentialKeys(query: string): string[] {\n  const keys: string[] = [];\n  \n  // Pattern: \"what does {entity} prefer for {thing}\"\n  const preferMatch = query.match(/what does (\\w+) prefer for ([\\w\\s]+)/i);\n  if (preferMatch) {\n    const entity = preferMatch[1].toLowerCase();\n    const thing = preferMatch[2].toLowerCase().replace(/\\s+/g, \"_\");\n    keys.push(`${entity}.preference.${thing}`);\n  }\n  \n  // Pattern: \"ryan's preference for X\"\n  const possessiveMatch = query.match(/(\\w+)'s preference for ([\\w\\s]+)/i);\n  if (possessiveMatch) {\n    const entity = possessiveMatch[1].toLowerCase();\n    const thing = possessiveMatch[2].toLowerCase().replace(/\\s+/g, \"_\");\n    keys.push(`${entity}.preference.${thing}`);\n  }\n  \n  return keys;\n}\n```\n\n3. **Integrate into recall flow**:\n```typescript\n// In recall() function, BEFORE vectorSearch/textSearch:\nconst kvResults = await kvLookup(ctx, input.query, scopeIds);\n\n// After ranking:\nconst ranked = await rankCandidatesPrimitive({ query, candidates, limit });\n\n// Boost KV results to top\nconst boostedResults = [\n  ...kvResults.map(f =\u003e ({ ...f, _boosted: true })),\n  ...ranked.ranked.filter(r =\u003e !kvResults.some(kv =\u003e kv._id === r._id))\n].slice(0, input.limit);\n```\n\n**Testing**: Query \"what does ryan prefer for package manager\" after storing \"Ryan prefers Bun\", verify Bun fact is top result.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:49.942376+01:00","updated_at":"2026-02-24T09:34:45.808365+01:00","dependencies":[{"issue_id":"engram-naa.4","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:49.944222+01:00","created_by":"daemon"}]}
{"id":"engram-naa.5","title":"Unit Tests: KV store mutations","description":"Unit tests for KV store mutations in `convex/kv-store.test.ts` (create new file).\n\n**File**: `convex/kv-store.test.ts` (new file)\n\n**Test Coverage**:\n1. **setKV - Insert new**:\n   - Create new KV entry\n   - Verify return value `{ kvId, updated: false }`\n   - Query back and validate fields\n   \n2. **setKV - Update existing**:\n   - Insert KV entry\n   - Call setKV again with same key+scope\n   - Verify return value `{ kvId, updated: true }`\n   - Validate `updatedAt` changed, `value` updated\n   \n3. **getKV - Scoped query**:\n   - Insert KV in scope A and scope B with same key\n   - Query with scopeId=A, verify correct entry returned\n   - Query with scopeId=B, verify different entry\n   \n4. **getKV - Global query** (no scopeId):\n   - Insert KV in multiple scopes\n   - Query without scopeId\n   - Verify returns first match (or most recent?)\n   \n5. **deleteKV**:\n   - Insert KV\n   - Delete by key+scope\n   - Verify getKV returns null\n   \n6. **listKVByScope**:\n   - Insert 5 KV entries in scope\n   - List with limit=3\n   - Verify returns 3 entries\n   \n7. **batchSetKV**:\n   - Insert 100 KV entries in batch\n   - Verify all inserted\n   - Test mixed insert/update batch\n\n**Framework**: Use Convex testing utilities (convex dev test environment).\n\n**Run**: `npm test` (add script to package.json if missing).","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:50.191064+01:00","updated_at":"2026-02-24T09:35:07.486754+01:00","dependencies":[{"issue_id":"engram-naa.5","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:50.192601+01:00","created_by":"daemon"}]}
{"id":"engram-naa.6","title":"E2E Test: Deterministic fact recall","description":"E2E test for deterministic fact storage and recall in `mcp-server/test/e2e/kv-recall.test.ts`.\n\n**File**: `mcp-server/test/e2e/kv-recall.test.ts` (new file)\n\n**Test Scenario**:\n1. **Setup**:\n   - Register test agent \"test-agent-kv\"\n   - Create scope \"test-kv-scope\"\n   \n2. **Store deterministic fact**:\n   - Call `memory_store_fact` with content: \"Ryan prefers Bun over npm for package management\"\n   - Verify fact created\n   - Verify KV entry created with key containing \"ryan.preference\"\n   \n3. **Recall with exact phrasing**:\n   - Call `memory_recall` with query: \"what does ryan prefer for package manager\"\n   - Verify top result is the Bun preference fact\n   - Verify `_kvMatch: true` or `_boosted: true` flag present\n   \n4. **Recall with different phrasing**:\n   - Call `memory_recall` with query: \"ryan's package manager preference\"\n   - Verify Bun fact still top result (KV lookup generalization)\n   \n5. **Update preference**:\n   - Store new fact: \"Ryan prefers pnpm over Bun now\"\n   - Recall \"ryan's package manager preference\"\n   - Verify pnpm fact is top result (KV updated)\n   \n6. **Scoped isolation**:\n   - Create second scope \"test-kv-scope-2\"\n   - Store \"Alice prefers npm\" in scope 2\n   - Recall in scope 1 with query \"package manager preference\"\n   - Verify only Ryan's preference returned (not Alice's)\n\n**Assertions**:\n- KV lookups complete in \u003c10ms\n- Deterministic facts always rank higher than vector-similar facts\n- Scope isolation maintained\n\n**Run**: `npm run test:e2e`","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-24T09:33:50.448953+01:00","updated_at":"2026-02-24T09:35:07.685797+01:00","dependencies":[{"issue_id":"engram-naa.6","depends_on_id":"engram-naa","type":"parent-child","created_at":"2026-02-24T09:33:50.450546+01:00","created_by":"daemon"}]}
{"id":"engram-ne6","title":"Refactor importance/decay/ranking to config-driven resolution","description":"Wire config resolver into importance scoring, decay cron, ranking formula, and prune/forget thresholds so behavior is prompt/config-native rather than hardcoded. Ensure deterministic fallback to hardcoded defaults for backwards compatibility. Add tests that scope-level overrides beat system_config and system_config beats fallback constants.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-15T00:33:53.72684+01:00","updated_at":"2026-02-15T00:49:13.005428+01:00","closed_at":"2026-02-15T00:49:13.005428+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-ne6","depends_on_id":"engram-5y2","type":"blocks","created_at":"2026-02-15T00:34:06.426713+01:00","created_by":"daemon"}]}
{"id":"engram-ppv","title":"Per-Agent Coefficient Profiles","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:14.743645+01:00","updated_at":"2026-02-24T09:33:14.743645+01:00"}
{"id":"engram-qcu","title":"Create memory_events table and schema","description":"Add memory_events table (eventType, payload, agentId, scopeId, timestamp, watermark) with indices by_agent_watermark and by_scope_watermark","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:38.080181+01:00","updated_at":"2026-02-15T00:58:48.913882+01:00","closed_at":"2026-02-15T00:58:48.913882+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-qcu","depends_on_id":"engram-c48","type":"blocks","created_at":"2026-02-15T00:39:11.470468+01:00","created_by":"daemon"}]}
{"id":"engram-rgd","title":"Performance and caching optimization pass","description":"Execute actionable performance tasks from plan: query index audit, mutation batching where practical, config cache refresh strategy in MCP server, cursor-based pagination for large result sets, and performance regression checks. Include before/after p95 metrics capture for critical paths (recall, get-context, store-fact).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-15T00:33:57.176222+01:00","updated_at":"2026-02-15T00:50:22.714722+01:00","closed_at":"2026-02-15T00:50:22.714722+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-rgd","depends_on_id":"engram-ne6","type":"blocks","created_at":"2026-02-15T00:34:09.100252+01:00","created_by":"daemon"},{"issue_id":"engram-rgd","depends_on_id":"engram-4rr","type":"blocks","created_at":"2026-02-15T00:34:09.513066+01:00","created_by":"daemon"}]}
{"id":"engram-ri0","title":"Convex mirror integration: actions + facts hooks","description":"Convex-side mirror integration (actions + facts hooks). This is the Convex action layer; the MCP-side reconciliation lib is in engram-8nz.\n\n**New Convex actions:**\n1. convex/actions/mirrorToVault.ts — Signal action triggered after storeFact/updateFact. Sets flag for vault-sync daemon to pick up. Simple implementation: log event, daemon polls.\n2. convex/actions/reconcileFromVault.ts — Handle file edits from vault (called by MCP vault-reconciler in engram-8nz). Three-way merge logic:\n   - Fetch DB fact by ID\n   - Compare updatedAt timestamps\n   - Field-level merge: HUMAN_FIELDS (content, tags, entities, priority, type) vs MACHINE_FIELDS (embedding, importance, decayFactor, synthesizedContext)\n   - If conflict detected: return conflict info for MCP layer to create .conflict file\n   - Update DB with merged values\n   - Return {success, conflicts[]}\n\n**Convex functions/facts.ts changes:**\n- Add mutation updateVaultPath(id, vaultPath) — Update fact.vaultPath after mirror\n- Add query getUnmirrored(limit) — Return facts where vaultPath == null, ordered by timestamp desc\n- Modify storeFact — Call mirrorToVault action after insert (non-blocking)\n\n**Field classification constants:**\n- HUMAN_FIELDS = [\"content\", \"tags\", \"entities\", \"priority\", \"type\"]\n- MACHINE_FIELDS = [\"embedding\", \"importance\", \"decayFactor\", \"synthesizedContext\"]\n- IMMUTABLE_FIELDS = [\"_id\", \"timestamp\", \"createdBy\", \"scopeId\"]\n\n**Tests:** reconcile-e2e.test.ts, conflict-e2e.test.ts\n**Performance:** Reconcile \u003c200ms p95\nRef: specs/obsidian-mirror-plan.md §2.2-2.4","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T23:00:27.123529+01:00","updated_at":"2026-02-14T23:24:36.042011+01:00","closed_at":"2026-02-14T23:24:36.042011+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-ri0","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T23:01:38.347058+01:00","created_by":"daemon"}]}
{"id":"engram-rq3","title":"Streaming Integration with Residual Novelty Detection","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:14.4946+01:00","updated_at":"2026-02-24T09:33:14.4946+01:00"}
{"id":"engram-rr7","title":"Episodic Memory / Episodes Table","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:13.309723+01:00","updated_at":"2026-02-24T09:33:13.309723+01:00"}
{"id":"engram-sll","title":"Context-budgeted recall with profiles","description":"Context-budgeted recall with explainability:\n\n**New file: mcp-server/src/lib/budget-aware-loader.ts**\n\n1. loadBudgetAwareContext(query, budget, convex) returns LoadedContext with facts, entities, themes, tokenUsage, and explainability array\n   - Budget allocation tiers: Critical 40%, Notable 40%, Background 10%, Entities 10%\n   - Fetch candidates via semantic search (limit 100, over-fetch then filter)\n   - Sort by: priority ASC then importanceScore DESC then timestamp DESC (deterministic)\n   - Fill tiers until budget exhausted\n   - Token estimation: chars/4 (rough estimate)\n\n2. detectQueryIntent(query) returns BudgetConfig based on keywords:\n   - decision/commit queries: 80% Critical, 20% Notable\n   - observation/recent queries: 10% Critical, 30% Notable, 60% Background\n   - Default: 40/40/10/10\n\n3. getInclusionReason(fact) explains why fact was loaded:\n   - Priority 0: Critical decision/commitment\n   - importanceScore \u003e0.8: High importance\n   - Created \u003c24h: Recent creation\n   - Default: Semantic relevance\n\n**Context profiles (from spec §5.1):**\n- Add profile parameter to memory_get_context: \"default\"|\"planning\"|\"incident\"|\"handoff\"\n- Each profile has different source ordering (structural, daily, search, graph, potential, contextual)\n\n**MCP tool enhancement (mcp-server/src/tools/get-context.ts):**\n- Add tokenBudget parameter (default 4000 from spec §5.2)\n- Add profile parameter (default \"default\")\n- Replace simple loader with loadBudgetAwareContext\n- Return facts, entities, themes, tokenUsage by tier, explainability array, truncated flag\n\n**Tests:** budget-aware-context-e2e.test.ts, budget-aware-latency.test.ts (\u003c200ms)\n**Performance:** Context load \u003c200ms, token efficiency 30% better, overflow rate \u003c2%\nRef: specs/obsidian-mirror-plan.md §5.1-5.3","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:50.889612+01:00","updated_at":"2026-02-14T23:25:46.767587+01:00","closed_at":"2026-02-14T23:25:46.767587+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-sll","depends_on_id":"engram-doo","type":"blocks","created_at":"2026-02-14T22:57:21.461965+01:00","created_by":"daemon"},{"issue_id":"engram-sll","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T22:57:22.260754+01:00","created_by":"daemon"}]}
{"id":"engram-srt","title":"Intent-Aware Retrieval Routing","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-24T09:33:13.088404+01:00","updated_at":"2026-02-24T09:33:13.088404+01:00"}
{"id":"engram-tsn","title":"Update enrichment to emit events","description":"Modify convex/functions/facts.ts storeFact, convex/actions/enrich.ts enrichFact to insert memory_events. Add getNextWatermark helper for monotonic sequence","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:43.824825+01:00","updated_at":"2026-02-15T00:58:50.057884+01:00","closed_at":"2026-02-15T00:58:50.057884+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-tsn","depends_on_id":"engram-qcu","type":"blocks","created_at":"2026-02-15T00:39:13.391888+01:00","created_by":"daemon"}]}
{"id":"engram-u51","title":"Engram Phase 1: Foundation — Convex Backend Setup","description":"# Engram Phase 1: Foundation\n\n## Background\nEngram is a unified multi-agent memory system for OpenClaw agents. It provides a shared memory layer where agents store atomic facts, recall context via semantic search, and share knowledge across devices and sessions. Local-first via LanceDB, cloud-synced through Convex, multimodal embeddings via Cohere Embed 4.\n\n## What This Epic Covers\nPhase 1 establishes the foundational data layer in Convex that every subsequent phase builds on:\n- Initialize Convex project\n- Deploy full 10-table schema (all optional future-phase fields included)\n- Implement CRUD mutations/queries for all 10 tables\n- Full-text search on facts with scope/type/agent filtering\n- Scope-based write permission enforcement on storeFact\n- Seed script to populate initial entities and default scopes\n\n## Why Full Schema From Day 1\nThe repo-research agent identified 17 schema discrepancies between PLAN.md (full) and the detailed plan (simplified). Decision: deploy PLAN.md's full schema with all future-phase fields as v.optional(). Convex schema changes require migrations; adding fields later is friction. Optional fields cost nothing until populated. Deploy once, never migrate schema.\n\n## Key Technical Decisions (Locked)\n- Backend: Convex (realtime, native vector search, scheduled functions, free tier)\n- Embeddings: Cohere Embed 4 (1024-dim, multimodal) — NOT OpenAI\n- MCP SDK: @modelcontextprotocol/sdk v1.x (Phase 2, not Phase 1)\n- Access control: Scope-based (NOT per-fact ACLs)\n- Memory lifecycle: 5-state machine (active → dormant → merged → archived → pruned)\n- Decay: Differential by fact type + emotional weight\n- Use lifecycleState (5 states) NOT status (3 states)\n\n## Phase 1 Scope Boundary\nIN SCOPE: Convex project init, schema, CRUD, full-text search, seed script, write permissions\nOUT OF SCOPE: MCP server (Phase 2), embeddings/enrichment (Phase 3), multi-agent (Phase 4), LanceDB sync (Phase 5), migration (Phase 6)\n\n## Success Criteria\n- npx convex dev runs successfully with all 10 tables visible in dashboard\n- Can insert a fact via storeFact mutation with scope write permission check\n- Full-text search on facts.content returns results filtered by scopeId, factType, createdBy\n- All 10 tables have basic CRUD operations\n- Seed script populates initial entities and default scopes\n- Write to scope with writePolicy: \"members\" fails for non-members\n- TypeScript strict mode, no any types in function args/returns\n\n## References\n- PLAN.md — Full schema (lines 89-289), Phase 1 checklist (lines 490-496)\n- docs/plans/2026-02-11-feat-engram-phase1-foundation-plan.md — Detailed Phase 1 plan\n- docs/research/tech-stack-best-practices.md — Convex patterns (1297 lines)\n- docs/INSTITUTIONAL_LEARNINGS.md — 8 critical implementation patterns","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-11T22:03:49.903178+01:00","updated_at":"2026-02-12T09:42:34.927436+01:00","closed_at":"2026-02-12T09:42:34.927436+01:00","close_reason":"Closed"}
{"id":"engram-u51.1","title":"Initialize Convex project","description":"# Initialize Convex Project\n\n## What\nRun npx create-convex in the Engram repo root to set up the Convex backend project. This creates the convex/ directory structure that all subsequent tasks depend on.\n\n## Why\nConvex is the cloud backend for Engram. It provides the schema DSL (defineSchema, defineTable, v validators), the function runtime (query, mutation, action), native vector search, scheduled functions (crons), and the ConvexHttpClient for external access. Without this initialization, no other Phase 1 work can proceed.\n\n## Steps\n1. Run npx create-convex in /Volumes/Main SSD/Developer/engram\n2. Select \"create a new project\" when prompted\n3. Verify convex/ directory created with:\n   - _generated/ (auto-generated types — commit per Convex best practices)\n   - tsconfig.json (Convex-specific TypeScript config)\n4. Verify root package.json updated with convex dependency (^1.17.0)\n5. Run npx convex dev to confirm project compiles with empty schema\n6. Update .gitignore if needed (Convex may add entries; convex/_generated/ should be committed)\n\n## Technical Notes\n- The current package.json only has beautiful-mermaid as dependency\n- Node.js 22+ and TypeScript 5.7+ are prerequisites\n- Convex free tier is sufficient for development\n- Environment variable CONVEX_URL will be obtained from this step\n\n## Acceptance Criteria\n- [ ] convex/ directory exists with _generated/ and tsconfig.json\n- [ ] package.json has convex ^1.17.0 in dependencies\n- [ ] npx convex dev compiles without errors (empty schema OK)\n- [ ] CONVEX_URL environment variable available (from .env.local or Convex dashboard)\n\n## Gotchas\n- npx create-convex may prompt for auth — need Convex account (free tier)\n- The generated convex/_generated/ directory SHOULD be committed (Convex convention)\n- Existing .gitignore already has .env and .env.local entries (good)\n\n## Estimate\n15 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:04:07.072193+01:00","updated_at":"2026-02-11T22:25:05.646734+01:00","closed_at":"2026-02-11T22:25:05.646755+01:00","dependencies":[{"issue_id":"engram-u51.1","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:07.074429+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.10","title":"Implement themes CRUD for hierarchical memory","description":"# Implement Themes CRUD\n\n## What\nCreate convex/functions/themes.ts for the themes table. Themes are thematic clusters of related facts — the EverMemOS MemScenes pattern for hierarchical memory.\n\n## Why\nThemes provide a higher-level view of memory. Instead of searching through hundreds of individual facts, agents can retrieve theme summaries. The weekly consolidation cron (Phase 6) will automatically group related facts into themes. Themes have their own embeddings for vector search.\n\n## Schema (from PLAN.md)\n- name: string\n- description: string\n- factIds: Id\u003c\"facts\"\u003e[] (facts in this theme)\n- entityIds: Id\u003c\"entities\"\u003e[] (related entities)\n- scopeId: Id\u003c\"memory_scopes\"\u003e\n- importance: float64\n- lastUpdated: number\n- embedding: float64[]? (1024-dim, for vector search on themes)\n\n## Functions to Implement\n\n### Mutations\n1. create(name, description, factIds, entityIds, scopeId, importance?)\n2. update(themeId, description?, factIds?, entityIds?, importance?)\n   - Update lastUpdated to Date.now()\n3. addFact(themeId, factId) — append to factIds (convenience)\n\n### Queries\n4. get(themeId)\n5. getByScope(scopeId, limit?) — using by_scope index\n6. searchThemes(query) — could use a searchIndex if added, or filter by name\n\n## Acceptance Criteria\n- [ ] Can create themes linked to scopes, facts, and entities\n- [ ] Can update theme description and add facts\n- [ ] getByScope returns themes for a given scope\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:52.954648+01:00","updated_at":"2026-02-11T22:25:07.618047+01:00","closed_at":"2026-02-11T22:25:07.61805+01:00","dependencies":[{"issue_id":"engram-u51.10","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:52.955901+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.10","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:52.957741+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.11","title":"Implement sync_log CRUD for LanceDB sync tracking","description":"# Implement Sync Log CRUD\n\n## What\nCreate convex/functions/sync.ts for the sync_log table. Tracks per-node LanceDB sync status for Phase 5.\n\n## Why\nEach device (Mac Mini, MacBook Air, MacBook Pro) runs its own LanceDB instance. The sync_log tracks what each node has synced, enabling differential sync (only pull facts since last sync). Phase 1 creates the CRUD; Phase 5 will use it for the actual sync daemon.\n\n## Schema (from PLAN.md)\n- nodeId: string — device identifier\n- lastSyncTimestamp: number — when this node last synced\n- factsSynced: number — total facts synced to this node\n- status: string — ok|error|syncing\n\n## Functions to Implement\n\n### Mutations\n1. updateSyncLog(nodeId, lastSyncTimestamp, factsSynced, status)\n   - Upsert by nodeId (create or update)\n\n### Queries\n2. getSyncStatus(nodeId) — using by_node index\n3. getFactsSince(timestamp, scopeId?) — internalQuery\n   - Return facts created/updated after timestamp\n   - Filter by scope if provided\n   - Used by sync daemon in Phase 5\n\n## Acceptance Criteria\n- [ ] Can create/update sync log entries\n- [ ] getSyncStatus returns correct status for a node\n- [ ] getFactsSince returns facts after a given timestamp\n\n## Estimate\n15 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:07:04.289418+01:00","updated_at":"2026-02-11T22:25:07.810836+01:00","closed_at":"2026-02-11T22:25:07.810844+01:00","dependencies":[{"issue_id":"engram-u51.11","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:04.290514+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.11","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:07:04.29189+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.12","title":"Write seed script to populate initial entities and scopes","description":"# Write Seed Script\n\n## What\nCreate scripts/seed.ts to populate the Convex database with initial entities, default scopes, and sample facts. Uses ConvexHttpClient to call mutations from outside the Convex runtime.\n\n## Why\nThe seed script bootstraps Engram with a useful starting state:\n- Default scopes (global, private-indy) for immediate use\n- Core entities (Ryan, Indy, OpenClaw, Engram, Convex, LanceDB, Cohere) with relationships\n- Sample facts to verify full-text search and CRUD work end-to-end\n- Provides a repeatable setup for development and testing\n\n## Seed Data\n\n### Default Scopes\n1. global — readPolicy: \"all\", writePolicy: \"all\", description: \"Shared knowledge base accessible to all agents\"\n2. private-indy — readPolicy: \"members\", writePolicy: \"members\", members: [\"indy\"], description: \"Indy's private memory space\"\n\n### Initial Entities\n| entityId | name | type | relationships |\n|----------|------|------|---------------|\n| entity-ryan | Ryan | person | created_by: entity-openclaw, works_with: entity-indy |\n| entity-indy | Indy | person | works_with: entity-ryan, part_of: entity-openclaw |\n| entity-openclaw | OpenClaw | project | created_by: entity-ryan |\n| entity-engram | Engram | project | part_of: entity-openclaw, depends_on: entity-convex, depends_on: entity-lancedb |\n| entity-convex | Convex | tool | related_to: entity-engram |\n| entity-lancedb | LanceDB | tool | related_to: entity-engram |\n| entity-cohere | Cohere | tool | related_to: entity-engram |\n\n### Sample Facts (3-5 facts for testing)\n- \"Engram uses Cohere Embed 4 for 1024-dim multimodal embeddings\" (factType: decision, scope: global)\n- \"Convex vector search is only available in actions, not queries\" (factType: learning, scope: global)\n- \"Ryan is the creator of OpenClaw and its agent ecosystem\" (factType: observation, scope: global)\n\n## Implementation Pattern\n\n```typescript\n// scripts/seed.ts\nimport { ConvexHttpClient } from \"convex/browser\";\nimport { api } from \"../convex/_generated/api\";\n\nconst client = new ConvexHttpClient(process.env.CONVEX_URL!);\n\nasync function seed() {\n  console.error(\"[seed] Starting...\");\n\n  // 1. Create scopes first (facts need scopeIds)\n  const globalScope = await client.mutation(api.functions.scopes.createScope, {\n    name: \"global\",\n    description: \"Shared knowledge base\",\n    members: [\"indy\"],\n    readPolicy: \"all\",\n    writePolicy: \"all\",\n  });\n\n  // 2. Register agent\n  await client.mutation(api.functions.agents.register, {\n    agentId: \"indy\",\n    name: \"Indy\",\n    capabilities: [\"memory\", \"code\", \"research\"],\n    defaultScope: \"private\",\n  });\n\n  // 3. Create entities\n  for (const entity of entities) {\n    await client.mutation(api.functions.entities.upsert, entity);\n  }\n\n  // 4. Store sample facts\n  for (const fact of sampleFacts) {\n    await client.mutation(api.functions.facts.storeFact, {\n      ...fact,\n      scopeId: globalScope,\n      createdBy: \"indy\",\n    });\n  }\n\n  console.error(\"[seed] Done!\");\n}\n\nseed().catch(console.error);\n```\n\n## Technical Notes\n- Use ConvexHttpClient (not internal functions) — seed runs OUTSIDE Convex runtime\n- Use console.error for all logging (stdout hygiene habit from MCP patterns)\n- Use process.env.CONVEX_URL for Convex connection\n- Run with: npx tsx scripts/seed.ts (or npx convex run scripts/seed if using Convex runner)\n- Batch pattern: Could use a single batch mutation for entities, but individual calls are fine for seed data (~10 items)\n- Make idempotent: upsert for entities, check-before-create for scopes\n\n## Acceptance Criteria\n- [ ] scripts/seed.ts exists and runs without errors\n- [ ] Creates global and private-indy scopes\n- [ ] Creates 7 initial entities with relationships\n- [ ] Stores 3+ sample facts in global scope\n- [ ] Facts are searchable via full-text search after seeding\n- [ ] Script is idempotent (running twice doesn't create duplicates)\n- [ ] All logging goes to stderr\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:07:29.875278+01:00","updated_at":"2026-02-11T22:25:07.967342+01:00","closed_at":"2026-02-11T22:25:07.967345+01:00","dependencies":[{"issue_id":"engram-u51.12","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:29.876065+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.3","type":"blocks","created_at":"2026-02-11T22:07:29.877179+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.4","type":"blocks","created_at":"2026-02-11T22:07:29.878235+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.5","type":"blocks","created_at":"2026-02-11T22:07:29.879421+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.6","type":"blocks","created_at":"2026-02-11T22:07:29.882011+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.13","title":"End-to-end verification and testing","description":"# End-to-End Verification\n\n## What\nVerify that all Phase 1 deliverables work correctly together. This is the final quality gate before Phase 2 can begin.\n\n## Why\nPhase 2 (MCP Server) depends entirely on Phase 1's Convex functions working correctly. Every MCP tool call ultimately hits a Convex mutation or query. If the foundation is broken, everything built on it will be broken.\n\n## Verification Checklist\n\n### Schema Verification\n- [ ] npx convex dev compiles without errors\n- [ ] Convex dashboard shows all 10 tables: facts, entities, conversations, sessions, agents, memory_scopes, signals, themes, sync_log\n- [ ] Each table has correct indexes visible in dashboard\n- [ ] vector_search index defined on facts (dimensions: 1024)\n- [ ] theme_search index defined on themes (dimensions: 1024)\n\n### CRUD Round-Trip Tests (via Convex dashboard or convex functions CLI)\n- [ ] Create scope → query scope → add member → verify\n- [ ] Register agent → query agent → update lastSeen → verify\n- [ ] Store fact (with scope write check) → get fact by ID → verify all fields\n- [ ] Store fact to unauthorized scope → verify rejection\n- [ ] Create entity → add relationship → query by entityId → verify\n- [ ] Create session → add conversation → link fact to conversation → verify chain\n- [ ] Record signal on fact → query signals by fact → verify\n- [ ] Create theme → add facts → query by scope → verify\n\n### Full-Text Search Tests\n- [ ] Search \"Cohere\" → returns fact about embeddings\n- [ ] Search \"Convex\" with factType filter → returns only matching type\n- [ ] Search with scopeId filter → returns only facts in that scope\n- [ ] Search with createdBy filter → returns only facts by that agent\n- [ ] Empty search → returns empty array (no crash)\n\n### Write Permission Tests\n- [ ] Agent in scope.members can write to scope with writePolicy: \"members\"\n- [ ] Agent NOT in scope.members is rejected for writePolicy: \"members\"\n- [ ] Any agent can write to scope with writePolicy: \"all\"\n- [ ] Only creator can write to scope with writePolicy: \"creator\"\n\n### Seed Script Verification\n- [ ] Run scripts/seed.ts → no errors\n- [ ] Run scripts/seed.ts AGAIN → no duplicates (idempotent)\n- [ ] Query entities → 7 entities with correct relationships\n- [ ] Query scopes → global and private-indy exist\n- [ ] Search facts → seed facts are searchable\n\n### TypeScript Quality\n- [ ] No any types in function args/returns\n- [ ] TypeScript strict mode enabled in convex/tsconfig.json\n- [ ] All Convex validators use v.* types\n\n## How to Test\n1. npx convex dev — verify compile\n2. npx tsx scripts/seed.ts — run seed\n3. Use Convex dashboard to inspect tables and run queries\n4. Alternatively, use convex CLI: npx convex run functions/facts:searchFacts '{\"query\": \"Cohere\"}'\n\n## Phase 1 Complete When\nALL of the above checks pass. This unblocks Phase 2 (MCP Server).\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:07:50.19959+01:00","updated_at":"2026-02-12T09:42:34.780978+01:00","closed_at":"2026-02-12T09:42:34.780991+01:00","dependencies":[{"issue_id":"engram-u51.13","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:50.200464+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.4","type":"blocks","created_at":"2026-02-11T22:07:50.201628+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.5","type":"blocks","created_at":"2026-02-11T22:07:50.202672+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.6","type":"blocks","created_at":"2026-02-11T22:07:50.203805+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.7","type":"blocks","created_at":"2026-02-11T22:07:50.204824+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.8","type":"blocks","created_at":"2026-02-11T22:07:50.205908+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.9","type":"blocks","created_at":"2026-02-11T22:07:50.207039+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.10","type":"blocks","created_at":"2026-02-11T22:07:50.208045+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.11","type":"blocks","created_at":"2026-02-11T22:07:50.209063+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.12","type":"blocks","created_at":"2026-02-11T22:07:50.210063+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.2","title":"Define complete 10-table schema in convex/schema.ts","description":"# Define Complete 10-Table Schema\n\n## What\nCreate convex/schema.ts with ALL 10 tables from PLAN.md (lines 89-289), including all optional future-phase fields. This is the single most important file in Phase 1 — it defines the entire data model.\n\n## Why\nUsing the full PLAN.md schema from day 1 prevents costly migrations when later phases add lifecycle management, emotional context, temporal links, etc. Convex schema changes require explicit migrations. Optional fields (v.optional()) cost nothing until populated. Deploy once, never migrate schema.\n\n## Schema Decision: Full vs Simplified\nThe repo-research agent found 17 schema discrepancies between PLAN.md and the detailed plan. Key decisions:\n- Use lifecycleState (5 states: active|dormant|merged|archived|pruned), NOT status (3 states)\n- Include factualSummary (SimpleMem compressed representation)\n- Include updatedAt (needed for sync tracking in Phase 5)\n- Include outcomeScore (MemRL learned utility — Phase 4+)\n- Include contributingAgents (collaborative memory provenance — Phase 4+)\n- Include emotionalContext + emotionalWeight (GIZIN emotional memory — Phase 3+)\n- Include temporalLinks (MAGMA multi-graph pattern — Phase 3+)\n- Include forgetScore, mergedInto, consolidatedFrom, supersededBy (lifecycle — Phase 3+)\n- Include conversations.threadFacts (facts-to-conversations linking)\n- Include sessions.conversationIds (session-conversation links)\n- Include agents.telos (PAI purpose/goal)\n- Include memory_scopes.memoryPolicy + idealStateCriteria (ALMA + PAI)\n\n## Tables to Define\n\n### 1. facts (26 fields, 5 indexes + 1 searchIndex + 1 vectorIndex)\nThe core memory unit. Stores atomic facts with embeddings, importance scores, lifecycle state, emotional context, temporal links, and scope.\n- Core fields: content, timestamp, source, entityIds, relevanceScore, accessedCount, importanceScore, createdBy, scopeId, tags, factType, embedding\n- Lifecycle: lifecycleState, mergedInto, consolidatedFrom, supersededBy, forgetScore\n- Emotional: emotionalContext, emotionalWeight\n- Multi-graph: temporalLinks (array of {targetFactId, relation, confidence})\n- Research-informed: factualSummary, updatedAt, outcomeScore, contributingAgents\n- References: conversationId\n- Indexes: by_scope, by_agent, by_type, by_importance, by_lifecycle\n- searchIndex: search_content (field: content, filters: scopeId, factType, createdBy)\n- vectorIndex: vector_search (field: embedding, dimensions: 1024, filters: scopeId)\n\n### 2. entities (name, type, relationships graph, 4 indexes)\n### 3. conversations (sessionId, participants, threadFacts, handoffs, 2 indexes)\n### 4. sessions (agentId, conversationIds, factCount, 2 indexes)\n### 5. agents (agentId, name, capabilities, telos, settings, 1 index)\n### 6. memory_scopes (name, members, policies, ISC, 1 index)\n### 7. signals (factId, agentId, signalType, value, 3 indexes)\n### 8. themes (name, factIds, entityIds, scopeId, embedding, 2 indexes + 1 vectorIndex)\n### 9. sync_log (nodeId, lastSyncTimestamp, status, 1 index)\n\n## Critical Constraints\n- vectorIndex dimensions MUST be 1024 (Cohere Embed 4 output dimension)\n- vectorIndex filterFields only support equality filters via q.eq()\n- searchIndex filterFields support equality filters for pre-filtering\n- All future-phase fields must be v.optional()\n- factType is a string union: decision|observation|plan|error|insight|correction|steering_rule|learning|session_summary\n- lifecycleState string union: active|dormant|merged|archived|pruned\n\n## Source of Truth\nCopy schema definitions EXACTLY from PLAN.md lines 89-289. The schema in the detailed plan (docs/plans/2026-02-11-feat-engram-unified-memory-system-plan.md lines 93-242) is the SIMPLIFIED version — do NOT use it.\n\n## Acceptance Criteria\n- [ ] convex/schema.ts defines all 10 tables\n- [ ] facts table has all 26 fields (most as v.optional())\n- [ ] All indexes defined (5 regular + 1 search + 1 vector on facts, plus others)\n- [ ] vectorIndex dimensions set to 1024\n- [ ] npx convex dev compiles without schema errors\n- [ ] Convex dashboard shows all 10 tables with correct structure\n\n## Estimate\n45 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:04:36.166167+01:00","updated_at":"2026-02-11T22:25:05.787684+01:00","closed_at":"2026-02-11T22:25:05.787686+01:00","dependencies":[{"issue_id":"engram-u51.2","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:36.166973+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.2","depends_on_id":"engram-u51.1","type":"blocks","created_at":"2026-02-11T22:04:36.168035+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.3","title":"Implement memory_scopes CRUD with write policy enforcement","description":"# Implement Memory Scopes CRUD\n\n## What\nCreate convex/functions/scopes.ts with full CRUD operations for the memory_scopes table, including the critical checkWriteAccess helper used by storeFact. This task must be completed BEFORE facts CRUD because storeFact depends on scope write permission enforcement.\n\n## Why\nScopes are the access control mechanism for Engram. Every fact belongs to a scope. Scopes define who can read and write. The storeFact mutation must check scope writePolicy before inserting — this is a PLAN.md Phase 1 requirement that was missing from the detailed plan.\n\nScope types:\n- private-{agentId}: Only that agent can read/write\n- team-{name}: Team members can read/write\n- project-{name}: Project-scoped with member lists\n- global: Everyone can read/write (public knowledge base)\n\n## Functions to Implement\n\n### Mutations\n1. createScope(name, description, members, readPolicy, writePolicy, retentionDays?)\n   - Validate name uniqueness via by_name index\n   - Default readPolicy: \"members\", writePolicy: \"members\"\n   - Return scope ID\n\n2. addMember(scopeId, agentId)\n   - Append to members array if not already present\n   - idempotent\n\n3. removeMember(scopeId, agentId)\n   - Filter from members array\n   - Error if agent is last member (can't have empty scope)\n\n### Queries\n4. getScope(scopeId) — by Convex _id\n5. getScopeByName(name) — using by_name index\n6. getPermittedScopes(agentId) — return all scopes where agentId is in members OR readPolicy is \"all\"\n\n### Internal Helper (exported as internalQuery)\n7. checkWriteAccess(scopeId, agentId) — returns boolean\n   - If writePolicy === \"all\": return true\n   - If writePolicy === \"members\": return members.includes(agentId)\n   - If writePolicy === \"creator\": return members[0] === agentId (first member is creator)\n\n## Write Policy Logic\n| writePolicy | Who Can Write |\n|-------------|---------------|\n| \"all\" | Any agent |\n| \"members\" | Only agents in scope.members array |\n| \"creator\" | Only first member (scope creator) |\n\n## Technical Notes\n- Use Convex v validators for all args\n- Use shared helper pattern: export both public query and internalQuery versions\n- getPermittedScopes needs to check both membership AND readPolicy === \"all\"\n- For Phase 1, no auth beyond agent ID trust boundary\n\n## Acceptance Criteria\n- [ ] Can create a new scope with name, description, members, policies\n- [ ] Can add/remove members from a scope\n- [ ] getPermittedScopes returns correct scopes for an agent\n- [ ] checkWriteAccess correctly enforces writePolicy for \"all\", \"members\", \"creator\"\n- [ ] Duplicate scope names are rejected\n- [ ] Cannot remove last member from a scope\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:04:55.227542+01:00","updated_at":"2026-02-11T22:25:05.911549+01:00","closed_at":"2026-02-11T22:25:05.911551+01:00","dependencies":[{"issue_id":"engram-u51.3","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:55.228438+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.3","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:04:55.229555+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.4","title":"Implement facts CRUD with write permission and full-text search","description":"# Implement Facts CRUD with Write Permission \u0026 Full-Text Search\n\n## What\nCreate convex/functions/facts.ts — the most important function file. Implements storeFact (with scope write permission check), read queries, full-text search, and access tracking. This is the core memory primitive that all MCP tools will use.\n\n## Why\nFacts are the atomic memory units in Engram. Every memory_store_fact, memory_recall, memory_search MCP tool call ultimately hits these functions. Getting storeFact right is critical — it must enforce scope write permissions, estimate importance without external calls, and prepare for async enrichment (Phase 3).\n\n## Functions to Implement\n\n### Mutations\n\n1. storeFact — THE critical mutation\n   Args: content, source?, entityIds?, tags?, factType?, scopeId, createdBy, conversationId?, emotionalContext?\n   Logic:\n   a. Check write permission: call checkWriteAccess(scopeId, createdBy) — throw if unauthorized\n   b. Estimate importance: keyword-based scoring (no external calls)\n      - High (0.9): decision, error, critical, breaking, failed, security\n      - Medium (0.6): fix, implement, create, build, update, deploy\n      - Low (0.3): note, observation, maybe, consider, minor\n      - Default: 0.5\n   c. Insert fact with defaults: relevanceScore=1.0, accessedCount=0, lifecycleState=\"active\", embedding=undefined\n   d. Comment out enrichment scheduler: // await ctx.scheduler.runAfter(0, internal.actions.enrich.enrichFact, { factId })\n   e. Return { factId, importanceScore }\n\n2. bumpAccess(factId)\n   - Increment accessedCount by 1\n   - Recalculate relevanceScore (simple: min(1.0, 0.5 + accessedCount * 0.05))\n\n3. updateEnrichment(factId, updates) — internalMutation\n   - Patch fact with embedding, factualSummary, entityIds, temporalLinks, etc.\n   - Set updatedAt to Date.now()\n   - Used by Phase 3 enrichment pipeline\n\n### Queries\n\n4. getFact(factId) — query by Convex _id\n5. getByIds(factIds: Id\u003c\"facts\"\u003e[]) — query multiple facts\n6. getByScope(scopeId, limit?, factType?) — using by_scope index\n7. getByAgent(createdBy, limit?) — using by_agent index\n\n### Full-Text Search\n\n8. searchFacts(query, scopeId?, factType?, createdBy?, limit?)\n   - Uses searchIndex(\"search_content\")\n   - Filter by scopeId, factType, createdBy (all optional)\n   - Default limit: 10\n   - Returns matching facts sorted by relevance\n\n## storeFact Implementation Pattern (from detailed plan lines 269-308)\n\n```typescript\nexport const storeFact = mutation({\n  args: {\n    content: v.string(),\n    source: v.optional(v.string()),\n    entityIds: v.optional(v.array(v.string())),\n    tags: v.optional(v.array(v.string())),\n    factType: v.optional(v.string()),\n    scopeId: v.id(\"memory_scopes\"),\n    createdBy: v.string(),\n    conversationId: v.optional(v.id(\"conversations\")),\n    emotionalContext: v.optional(v.string()),\n  },\n  returns: v.object({ factId: v.id(\"facts\"), importanceScore: v.number() }),\n  handler: async (ctx, args) =\u003e {\n    // 1. Check write permission\n    const scope = await ctx.db.get(args.scopeId);\n    if (!scope) throw new Error(\"Scope not found\");\n    if (scope.writePolicy === \"members\" \u0026\u0026 !scope.members.includes(args.createdBy)) {\n      throw new Error(\"Agent not authorized to write to this scope\");\n    }\n    // ... (see Phase 1 plan for full implementation)\n  },\n});\n```\n\n## Full-Text Search Pattern\n\n```typescript\nexport const searchFacts = query({\n  args: {\n    query: v.string(),\n    scopeId: v.optional(v.id(\"memory_scopes\")),\n    factType: v.optional(v.string()),\n    createdBy: v.optional(v.string()),\n    limit: v.optional(v.number()),\n  },\n  handler: async (ctx, args) =\u003e {\n    let search = ctx.db.query(\"facts\").withSearchIndex(\"search_content\", (q) =\u003e {\n      let s = q.search(\"content\", args.query);\n      if (args.scopeId) s = s.eq(\"scopeId\", args.scopeId);\n      if (args.factType) s = s.eq(\"factType\", args.factType);\n      if (args.createdBy) s = s.eq(\"createdBy\", args.createdBy);\n      return s;\n    });\n    return await search.take(args.limit ?? 10);\n  },\n});\n```\n\n## Critical Constraints\n- Mutations retry automatically on transient errors — make storeFact idempotent-safe\n- Don't use console.log (reserved for MCP stdio in Phase 2) — use console.error for debugging\n- The enrichment scheduler call should be COMMENTED OUT in Phase 1 (action doesn't exist yet)\n- Use shared helper pattern for getFact (public query + internalQuery)\n- estimateImportance is a plain function, not a Convex function (no ctx needed)\n\n## Acceptance Criteria\n- [ ] storeFact mutation works with scope write permission check\n- [ ] storeFact rejects unauthorized writes (writePolicy: \"members\" with non-member)\n- [ ] getFact and getByIds return correct facts\n- [ ] searchFacts returns full-text search results with scope/type/agent filtering\n- [ ] bumpAccess increments count and updates relevanceScore\n- [ ] updateEnrichment (internal) can patch fact with enrichment data\n- [ ] estimateImportance returns correct scores for high/medium/low keywords\n\n## Estimate\n60 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:05:26.070928+01:00","updated_at":"2026-02-11T22:25:06.042923+01:00","closed_at":"2026-02-11T22:25:06.042925+01:00","dependencies":[{"issue_id":"engram-u51.4","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:05:26.071768+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.4","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:05:26.072955+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.4","depends_on_id":"engram-u51.3","type":"blocks","created_at":"2026-02-11T22:05:26.073956+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.5","title":"Implement entities CRUD with relationship graph","description":"# Implement Entities CRUD\n\n## What\nCreate convex/functions/entities.ts with CRUD operations for the entities table. Entities are named concepts (person, project, company, concept, tool) with a relationship graph.\n\n## Why\nEntities are the knowledge graph nodes in Engram. They represent people (Ryan, Indy), projects (OpenClaw, Engram), tools (Convex, LanceDB, Cohere), etc. Facts link to entities via entityIds array. The entity extraction pipeline (Phase 3) will auto-create entities from fact content.\n\n## Entity Schema (from PLAN.md)\n- entityId: string — human-readable ID like \"entity-ryan\", \"entity-convex\"\n- name: string — display name\n- type: string — person|project|company|concept|tool\n- firstSeen, lastSeen: number — timestamps\n- metadata: v.any() — flexible key-value store\n- relationships: array of {targetId, relationType, since?}\n  - Relation types: created_by|depends_on|works_with|part_of|related_to\n- importanceScore: float64\n- accessCount: number\n- createdBy: string — agent ID\n\n## Functions to Implement\n\n### Mutations\n1. upsert(entityId, name, type, metadata?, createdBy)\n   - Check if entity exists via by_entity_id index\n   - If exists: update lastSeen, merge metadata, increment accessCount\n   - If new: create with firstSeen=lastSeen=Date.now(), accessCount=1, relationships=[], importanceScore=0.5\n\n2. addRelationship(entityId, targetId, relationType, since?)\n   - Find entity via by_entity_id index\n   - Check for duplicate relationship (same targetId + relationType)\n   - Append to relationships array if new\n\n3. updateImportance(entityId, importanceScore) — internalMutation for Phase 3\n\n### Queries\n4. get(entityConvexId) — by Convex _id\n5. getByEntityId(entityId) — using by_entity_id index\n6. getByType(type, limit?) — using by_type index\n7. searchEntities(query, limit?) — full-text search on entity name\n\n## Technical Notes\n- entityId is the human-readable string (e.g., \"entity-ryan\"), NOT the Convex _id\n- The by_entity_id index enables O(1) lookup by string ID\n- metadata is v.any() for flexibility — stores arbitrary key-value data\n- Relationships form a directed graph: entity A relates_to entity B\n- The seed script will create initial entities using upsert\n\n## Acceptance Criteria\n- [ ] Can create new entity via upsert\n- [ ] Upsert on existing entity updates lastSeen and increments accessCount\n- [ ] Can add relationships between entities\n- [ ] Duplicate relationships are ignored (idempotent)\n- [ ] getByEntityId returns correct entity\n- [ ] searchEntities uses full-text search index on name field\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:05:44.180853+01:00","updated_at":"2026-02-11T22:25:06.177017+01:00","closed_at":"2026-02-11T22:25:06.177019+01:00","dependencies":[{"issue_id":"engram-u51.5","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:05:44.181937+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.5","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:05:44.183246+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.6","title":"Implement agents CRUD with registration","description":"# Implement Agents CRUD\n\n## What\nCreate convex/functions/agents.ts with CRUD operations for the agents table. Agents are the identities that interact with Engram memory.\n\n## Why\nEvery memory operation is attributed to an agent. Agent registration is the first step when an agent connects to Engram. The agents table tracks capabilities, last seen time, fact count, default scope, and optional telos (purpose/goal from PAI pattern).\n\n## Agent Schema (from PLAN.md)\n- agentId: string — human-readable like \"indy\", \"coder-1\", \"ml-worker\"\n- name: string — display name\n- nodeId: string? — OpenClaw node identifier\n- capabilities: string[] — what the agent can do\n- lastSeen: number — timestamp of last activity\n- factCount: number — total facts created by this agent\n- defaultScope: string — \"private\"|\"team\"|\"public\"\n- telos: string? — purpose/goal (PAI pattern, e.g., \"Ship code faster\")\n- settings: any? — agent-specific memory configuration\n\n## Functions to Implement\n\n### Mutations\n1. register(agentId, name, capabilities, defaultScope, nodeId?, telos?, settings?)\n   - Check if agent exists via by_agent_id index\n   - If exists: update lastSeen, capabilities, nodeId, telos, settings\n   - If new: create with lastSeen=Date.now(), factCount=0\n   - Also create private scope \"private-{agentId}\" if not exists\n   - Return agent Convex _id\n\n2. updateLastSeen(agentId) — called on every agent interaction\n   - Update lastSeen to Date.now()\n\n3. incrementFactCount(agentId) — internalMutation\n   - Increment factCount by 1 (called by storeFact)\n\n### Queries\n4. get(agentConvexId) — by Convex _id\n5. getByAgentId(agentId) — using by_agent_id index\n6. listAgents(limit?) — list all agents ordered by lastSeen\n\n## Technical Notes\n- Agent registration should be idempotent (re-registering updates, doesn't create duplicate)\n- The register mutation should also create the agent's private scope (depends on scopes CRUD existing, but can be done inline)\n- factCount is denormalized for quick access — incremented by storeFact\n- defaultScope determines where facts go when scopeId is not explicitly provided\n\n## Acceptance Criteria\n- [ ] Can register a new agent with capabilities and telos\n- [ ] Re-registration updates existing agent (idempotent)\n- [ ] updateLastSeen correctly timestamps\n- [ ] getByAgentId returns correct agent via index\n- [ ] listAgents returns agents sorted by lastSeen\n\n## Estimate\n25 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:06:00.876537+01:00","updated_at":"2026-02-11T22:25:06.309545+01:00","closed_at":"2026-02-11T22:25:06.309547+01:00","dependencies":[{"issue_id":"engram-u51.6","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:00.878563+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.6","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:00.88125+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.7","title":"Implement conversations CRUD with handoff tracking","description":"# Implement Conversations CRUD\n\n## What\nCreate convex/functions/conversations.ts for the conversations table. Conversations thread facts together, track participants, and record agent handoffs.\n\n## Why\nConversations provide temporal grouping of facts within a session. They track which agents participated and when handoffs occurred (Agent A passes context to Agent B). The threadFacts array links facts to their conversation for retrieval.\n\n## Schema (from PLAN.md)\n- sessionId: Id\u003c\"sessions\"\u003e\n- participants: string[] (agent IDs)\n- threadFacts: Id\u003c\"facts\"\u003e[] (linked facts)\n- contextSummary: string\n- importance: float64\n- tags: string[]\n- handoffs: array of {fromAgent, toAgent, timestamp, contextSummary}\n\n## Functions to Implement\n\n### Mutations\n1. create(sessionId, participants, contextSummary?, tags?) — create new conversation\n2. addFact(conversationId, factId) — append to threadFacts array\n3. addHandoff(conversationId, fromAgent, toAgent, contextSummary) — record agent handoff\n4. updateSummary(conversationId, contextSummary) — update context summary\n\n### Queries\n5. get(conversationId) — by Convex _id\n6. getBySession(sessionId) — using by_session index\n\n## Conversation Boundary Logic (from SpecFlow analysis)\n- Time gap \u003e 30 minutes OR agent explicitly calls boundary → new conversation\n- This logic lives in the MCP server (Phase 2), not in Convex functions\n\n## Acceptance Criteria\n- [ ] Can create conversations linked to sessions\n- [ ] Can add facts to conversation threadFacts\n- [ ] Can record handoffs between agents\n- [ ] getBySession returns conversations for a session\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:14.540067+01:00","updated_at":"2026-02-11T22:25:07.17318+01:00","closed_at":"2026-02-11T22:25:07.173182+01:00","dependencies":[{"issue_id":"engram-u51.7","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:14.541431+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.7","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:14.542843+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.8","title":"Implement sessions CRUD","description":"# Implement Sessions CRUD\n\n## What\nCreate convex/functions/sessions.ts for the sessions table. Sessions track agent activity periods.\n\n## Schema (from PLAN.md)\n- agentId: string\n- startTime: number\n- lastActivity: number\n- conversationIds: Id\u003c\"conversations\"\u003e[]\n- factCount: number\n- contextSummary: string\n- parentSession: Id\u003c\"sessions\"\u003e? (for nested/resumed sessions)\n- nodeId: string? (OpenClaw node)\n\n## Functions to Implement\n\n### Mutations\n1. create(agentId, contextSummary?, parentSession?, nodeId?) — start new session\n2. updateActivity(sessionId) — update lastActivity timestamp\n3. addConversation(sessionId, conversationId) — append to conversationIds\n4. incrementFactCount(sessionId) — internalMutation\n\n### Queries\n5. get(sessionId)\n6. getByAgent(agentId, limit?) — using by_agent index, ordered by startTime\n7. getActive(agentId) — most recent session for an agent\n\n## Acceptance Criteria\n- [ ] Can create sessions linked to agents\n- [ ] updateActivity correctly timestamps\n- [ ] getByAgent returns sessions ordered by startTime\n- [ ] getActive returns the most recent session\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:26.582497+01:00","updated_at":"2026-02-11T22:25:07.321437+01:00","closed_at":"2026-02-11T22:25:07.32144+01:00","dependencies":[{"issue_id":"engram-u51.8","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:26.583468+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.8","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:26.584755+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.9","title":"Implement signals CRUD for feedback tracking","description":"# Implement Signals CRUD\n\n## What\nCreate convex/functions/signals.ts for the signals table. Signals capture feedback on facts — explicit ratings and implicit sentiment from the PAI feedback loop pattern.\n\n## Why\nSignals are how agents communicate which memories were useful. This enables learned utility scoring (MemRL pattern) in later phases. The PAI system uses explicit ratings (1-10) and implicit sentiment (-1.0 to 1.0) to steer memory retrieval.\n\n## Schema (from PLAN.md)\n- factId: Id\u003c\"facts\"\u003e? (optional — some signals are session-level)\n- sessionId: Id\u003c\"sessions\"\u003e? (optional)\n- agentId: string\n- signalType: string — explicit_rating|implicit_sentiment|failure\n- value: number — 1-10 for ratings, -1.0 to 1.0 for sentiment\n- comment: string?\n- confidence: float64?\n- context: string?\n- timestamp: number\n\n## Functions to Implement\n\n### Mutations\n1. recordSignal(factId?, sessionId?, agentId, signalType, value, comment?, confidence?, context?)\n   - Validate: at least one of factId or sessionId must be provided\n   - Validate: value range depends on signalType (1-10 for rating, -1.0-1.0 for sentiment)\n   - Set timestamp to Date.now()\n\n### Queries\n2. getByFact(factId, limit?) — using by_fact index\n3. getByAgent(agentId, limit?) — using by_agent index\n4. getByType(signalType, limit?) — using by_type index\n\n## Acceptance Criteria\n- [ ] Can record signals with fact or session reference\n- [ ] Validation rejects signals without factId AND sessionId\n- [ ] getByFact returns signals for a specific fact\n- [ ] getByAgent returns signals from a specific agent\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:39.616471+01:00","updated_at":"2026-02-11T22:25:07.467715+01:00","closed_at":"2026-02-11T22:25:07.467719+01:00","dependencies":[{"issue_id":"engram-u51.9","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:39.617434+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.9","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:39.618846+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u6o","title":"Phase 4: Multi-Agent + Crons — multi-scope recall, 7 cron jobs, handoff tracking","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:51:00.561603+01:00","updated_at":"2026-02-12T10:06:05.587025+01:00","closed_at":"2026-02-12T10:06:05.587025+01:00","close_reason":"Completed"}
{"id":"engram-uah","title":"Vault file watcher: MD→Convex bidirectional import","description":"Vault file watcher for bidirectional sync (integrated in vault-sync daemon):\n\n**Implementation (part of mcp-server/src/daemons/vault-sync.ts from engram-7yr):**\n\nUsing chokidar to watch vault/ directory:\n- Watch patterns: vault/**/*.md (ignore dot files)\n- Events: change, add (not delete - archive in DB instead)\n- Options: ignoreInitial: true (don't trigger on startup), persistent: true\n\n**On file change:**\n1. Read file content\n2. Parse frontmatter + body\n3. Extract fact ID from frontmatter.id\n4. Call reconcileFromVault action (from engram-8nz)\n5. If conflicts detected: create .conflict file\n6. If success: log sync event\n\n**Error handling:**\n- Parse errors: log + skip file\n- Missing ID: log warning + skip\n- Convex connection errors: exponential backoff retry\n- File permission errors: log + skip\n\n**Reconciliation flow:**\nvault file edited → chokidar detects change → reconcileFromVault action → three-way merge → DB updated OR conflict file created\n\n**Performance:**\n- Event handling \u003c100ms\n- Reconciliation \u003c200ms p95\n- No blocking of other daemon operations\n\n**Tests:** file-watcher-e2e.test.ts (edit file → event triggered → DB updated), conflict-detection-e2e.test.ts (concurrent edits → conflict file)\nRef: VAULT_INTEGRATION_PLAN.md Phase 3.3, Phase 3.4","status":"closed","priority":3,"issue_type":"task","created_at":"2026-02-14T22:57:02.366752+01:00","updated_at":"2026-02-14T23:25:41.78073+01:00","closed_at":"2026-02-14T23:25:41.78073+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-uah","depends_on_id":"engram-dxj","type":"blocks","created_at":"2026-02-14T22:57:23.950393+01:00","created_by":"daemon"},{"issue_id":"engram-uah","depends_on_id":"engram-8nz","type":"blocks","created_at":"2026-02-14T23:07:58.964782+01:00","created_by":"daemon"}]}
{"id":"engram-uqr","title":"Phase 2: MCP Server — 12 tools, stdio transport, ConvexHttpClient","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:50:57.325257+01:00","updated_at":"2026-02-12T10:06:05.281267+01:00","closed_at":"2026-02-12T10:06:05.281267+01:00","close_reason":"Completed"}
{"id":"engram-uvz","title":"Hierarchical Vault Index Improvement","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-24T09:33:14.013495+01:00","updated_at":"2026-02-24T09:33:14.013495+01:00"}
{"id":"engram-vgb","title":"Decompose memory_summarize and memory_prune","description":"Split into primitives: memory_list_stale_facts, memory_mark_facts_merged, memory_mark_facts_pruned. Let agents compose filtering logic","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:38:34.44353+01:00","updated_at":"2026-02-15T00:58:48.155158+01:00","closed_at":"2026-02-15T00:58:48.155158+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-vgb","depends_on_id":"engram-ai3","type":"blocks","created_at":"2026-02-15T00:39:05.773245+01:00","created_by":"daemon"}]}
{"id":"engram-vj6","title":"MCP tools: query_vault + memory_export_graph","description":"New MCP tools for vault querying and graph export:\n\n**1. memory_query_vault (mcp-server/src/tools/query-vault.ts):**\n- Direct vault file queries without Convex\n- Parameters: query (string), filters (type, priority, scope)\n- Scan vault index files for matches\n- Load facts from markdown files\n- Use case: Fast local queries when Convex unavailable\n- Returns: facts[], source: 'vault', latencyMs\n\n**2. memory_export_graph (mcp-server/src/tools/export-graph.ts):**\n- Export memory graph to Obsidian-compatible JSON\n- Uses graph-exporter.ts (in engram-43e)\n- Parameters: outputPath (default: vault/.obsidian/graph.json)\n- Format: {nodes: [{id, label, type, group}], links: [{source, target, type}]}\n- Includes fact→entity edges (type: 'mentions')\n- Includes entity→entity edges (type: relationship type)\n- Use case: Obsidian graph visualization\n- Returns: {success, nodeCount, linkCount, outputPath}\n\n**MCP server registration (mcp-server/src/index.ts):**\n- Register both tools with MCP protocol\n- Add to tool list in server initialization\n\n**Tests:** query-vault.test.ts (vault queries work), export-graph.test.ts (valid Obsidian JSON format)\n**Performance:** Query vault \u003c150ms, graph export \u003c2s for 10k facts\nRef: VAULT_INTEGRATION_PLAN.md Phase 1.3.2, Phase 4.5","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:31.532522+01:00","updated_at":"2026-02-14T23:25:09.113482+01:00","closed_at":"2026-02-14T23:25:09.113482+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-vj6","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:44.167653+01:00","created_by":"daemon"},{"issue_id":"engram-vj6","depends_on_id":"engram-gxr","type":"blocks","created_at":"2026-02-14T23:02:12.639062+01:00","created_by":"daemon"}]}
{"id":"engram-waf","title":"Create vault-format.ts: Fact↔Markdown serialization","description":"Create mcp-server/src/lib/vault-format.ts with comprehensive markdown serialization:\n\n**Main Functions:**\n1. generateFrontmatter(fact) — Convert fact to YAML frontmatter with all fields (id, type, scope, priority, lifecycleState, tags, entities, timestamps, importance, confidence, importanceTier, vaultPath, observationTier, etc.). Omit null/undefined. Format dates as ISO 8601.\n2. generateMarkdownBody(fact) — Convert content to markdown with H1 title, context blockquote, main content, Related Facts section (wiki-links), Entities section, Provenance footer.\n3. parseFrontmatter(fileContent) — Parse YAML + body, validate required fields, convert date strings to Date objects, handle malformed YAML gracefully, return {frontmatter, body, errors}.\n4. generateFilename(fact) — Format: {slugified-title}-{short-id}.md (max 50 chars slug, 8-char convexId prefix). Use slugify npm package.\n5. computeFolderPath(fact, vaultRoot) — Route by factType using FACT_TYPE_TO_FOLDER map from spec §1.2. Scope prefix: private-{agentId}/, team-{teamId}/, etc.\n6. extractWikiLinks(content) — Find all [[Name]] links, return array of {name, startIndex, endIndex}.\n\n**Dependencies:** js-yaml, slugify\n**Tests:** Unit tests for each function, golden tests for round-trip (fact → markdown → fact)\n**Performance target:** Format/parse \u003c10ms per fact\nRef: specs/obsidian-mirror-plan.md §1.1-1.3, Phase 2","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:13.806981+01:00","updated_at":"2026-02-14T23:24:31.240256+01:00","closed_at":"2026-02-14T23:24:31.240256+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-waf","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T22:57:17.70699+01:00","created_by":"daemon"},{"issue_id":"engram-waf","depends_on_id":"engram-46g","type":"blocks","created_at":"2026-02-14T23:07:29.234192+01:00","created_by":"daemon"}]}
{"id":"engram-wii","title":"Add config/event schema foundations (system_config, memory_policies, memory_events, agent identity fields)","description":"Implement schema primitives required by the plan: system_config table for prompt-native behavior, memory_policies for scope overrides, and memory_events for reactive propagation. Extend agents with identity context fields used during context injection. Add indexes exactly as needed for lookup paths (by_key, by_category, by_scope_key, by_created/by_scope_created). Include migration-safe defaults and verification queries proving no existing fact/entity/agent records are invalidated.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-15T00:33:52.882727+01:00","updated_at":"2026-02-15T00:45:34.331922+01:00","closed_at":"2026-02-15T00:45:34.331922+01:00","close_reason":"Closed"}
{"id":"engram-wzv","title":"Phase 6: Migration + Polish — import, crons, benchmarks","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T10:02:09.557812+01:00","updated_at":"2026-02-12T10:07:30.097634+01:00","closed_at":"2026-02-12T10:07:30.097634+01:00","close_reason":"Completed"}
{"id":"engram-x95","title":"Rust/WASM acceleration scaffold (deferred)","description":"Track deferred rust/wasm acceleration milestone from specs/UNIMPLEMENTED.md.","status":"closed","priority":4,"issue_type":"task","created_at":"2026-02-14T23:53:28.300356+01:00","updated_at":"2026-02-14T23:54:17.055068+01:00","closed_at":"2026-02-14T23:54:17.055068+01:00","close_reason":"Closed"}
{"id":"engram-ykh","title":"Entity backlinks + graph edge consistency","description":"Entity backlinks consistency and graph edge validation:\n\n**This task focuses on maintaining consistency between:**\n1. Fact content wiki-links [[Entity]]\n2. Entity backlinks array in entities table\n3. Fact entities array field\n4. Graph export edges\n\n**Implementation (convex/functions/entities.ts):**\n\n1. updateBacklinks(factId, entityNames):\n   - For each entity name in the fact\n   - Find entity by name\n   - Add to entity.backlinks if not exists: {factId, factType, linkedAt}\n   - Remove from backlinks if entity no longer mentioned\n\n2. validateBacklinks() — Periodic validation:\n   - For each entity, check backlinks array\n   - Verify each backlinked fact still exists and mentions entity\n   - Remove stale backlinks (fact deleted or entity removed)\n   - Log inconsistencies\n\n3. rebuildBacklinks() — Full rebuild:\n   - Clear all entity.backlinks arrays\n   - Scan all active facts\n   - Extract wiki-links from content\n   - Rebuild backlinks from scratch\n   - Use case: Fix inconsistencies after bugs\n\n**Integration points:**\n- storeFact: call updateBacklinks after insert\n- updateFact: call updateBacklinks after update\n- deleteFact: call updateBacklinks to remove\n\n**Convex cron (optional):**\n- Schedule validateBacklinks() daily\n- Fix inconsistencies automatically\n- Log warnings for manual review\n\n**Tests:** backlink-consistency.test.ts (store/update/delete maintains consistency), backlink-validation.test.ts (detect and fix stale backlinks)\n**Performance:** Update backlinks \u003c50ms, full rebuild \u003c30s for 10k entities\nRef: VAULT_INTEGRATION_PLAN.md Phase 4.4","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:31.71662+01:00","updated_at":"2026-02-14T23:25:09.08173+01:00","closed_at":"2026-02-14T23:25:09.08173+01:00","close_reason":"Closed","dependencies":[{"issue_id":"engram-ykh","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:58.67423+01:00","created_by":"daemon"}]}
{"id":"engram-ywx","title":"Schema changes: add vault mirror fields to facts table","description":"Add vault mirror fields to convex/schema.ts facts table:\n\n**New fields:**\n1. vaultPath (v.optional(v.string())) — Relative path in vault (e.g., \"private-indy/decisions/2026-02-14-foo.md\")\n2. vaultSyncedAt (v.optional(v.number())) — Last sync timestamp\n3. confidence (v.optional(v.float64())) — 0.0-1.0 confidence score (from spec §1.4)\n4. importanceTier (v.optional(v.string())) — \"structural\"|\"potential\"|\"contextual\"\n5. observationTier (v.optional(v.string())) — \"critical\"|\"notable\"|\"background\" (flat field, no dot notation)\n6. observationCompressed (v.optional(v.boolean())) — Whether background compression ran\n7. observationOriginalContent (v.optional(v.string())) — Content before compression\n\n**New indices:**\n- .index(\"by_vault_path\", [\"vaultPath\"])\n- .index(\"by_vault_synced\", [\"vaultSyncedAt\"])\n- .index(\"by_observation_tier\", [\"observationTier\", \"timestamp\"])\n- .index(\"unmirrored\", [\"vaultPath\", \"lifecycleState\"])\n\nNOTE: Convex does not support dot-notation field names. All observation.* fields from the original plan are flattened to observationTier, observationCompressed, observationOriginalContent.\nNOTE: facts table uses \"timestamp\" not \"createdAt\", and \"lifecycleState\" not \"status\".\n\nPerformance target: Schema migration \u003c1s, zero downtime.\nRef: specs/obsidian-mirror-plan.md §1.4, VAULT_INTEGRATION_PLAN.md Phase 1.3.1, Phase 2.8, Phase 6.8","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:07.968133+01:00","updated_at":"2026-02-14T23:24:12.789753+01:00","closed_at":"2026-02-14T23:24:12.789753+01:00","close_reason":"Closed"}
