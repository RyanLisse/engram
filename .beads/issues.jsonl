{"id":"engram-0ro","title":"Validation suite: golden tests + regression benchmarks","description":"Comprehensive validation suite: golden tests, regression, benchmarks:\n\n**Test structure:**\ntests/\n  ├── unit/ (9 files)\n  │   ├── vault-writer.test.ts — File creation, atomic writes, folder structure\n  │   ├── vault-reader.test.ts — Parse frontmatter, handle malformed YAML\n  │   ├── vault-reconciler.test.ts — Three-way merge, conflict detection\n  │   ├── wiki-link-parser.test.ts — Extract links, edge cases\n  │   ├── auto-linker.test.ts — Entity matching, duplicate avoidance\n  │   ├── vault-indexer.test.ts — Index generation, sorting\n  │   ├── budget-aware-loader.test.ts — Token counting, tier allocation\n  │   ├── frontmatter-generator.test.ts — All fact types, valid YAML\n  │   └── slug-generator.test.ts — Filename sanitization\n  ├── integration/ (7 files)\n  │   ├── write-through-e2e.test.ts — Store fact → file appears \u003c5s\n  │   ├── reconcile-e2e.test.ts — Edit file → DB updates\n  │   ├── conflict-e2e.test.ts — Concurrent edits → conflict file\n  │   ├── auto-linking-e2e.test.ts — Entity mentions → wiki-links\n  │   ├── index-first-e2e.test.ts — Query → index scan → results\n  │   ├── observation-compression-e2e.test.ts — Classify → compress\n  │   └── budget-aware-context-e2e.test.ts — Budget enforcement\n  ├── golden/ (4 files)\n  │   ├── format/decision.golden.md — Expected markdown for decision\n  │   ├── format/lesson.golden.md — Expected markdown for lesson\n  │   ├── format/entity.golden.md — Expected markdown for entity\n  │   └── retrieval/evaluate-relevance.test.ts — Query set, relevance@5\n  ├── benchmarks/ (1 file)\n  │   └── before-after.test.ts — Latency, relevance, token efficiency\n  └── regression/ (5 files)\n      ├── core-api.test.ts — All MCP tools still work\n      ├── enrichment.test.ts — Embeddings, entities, importance\n      ├── decay.test.ts — Decay cron still runs\n      ├── consolidation.test.ts — Theme merging still works\n      └── sync.test.ts — LanceDB sync still works\n\n**Golden query set (in retrieval/):**\n- 20+ queries with expected fact IDs\n- Min relevance thresholds per query\n- Cover all fact types and priority tiers\n\n**Performance benchmarks:**\n- Retrieval latency: before (450ms) vs after (\u003c200ms index, \u003c500ms semantic)\n- Relevance@5: before (0.72) vs after (\u003e0.85)\n- Token efficiency: before (2000) vs after (\u003c1400)\n- Sync reliability: 99.99% over 10k ops\n\n**CI Integration:**\n- Run on every PR, block merge if fails\n- Coverage target \u003e80%\n- Performance regression gate: \u003e10% slower = fail\n\nRef: VAULT_INTEGRATION_PLAN.md Phase 8 (sections 8.3-8.9)","status":"open","priority":4,"issue_type":"task","created_at":"2026-02-14T22:57:11.869078+01:00","updated_at":"2026-02-14T23:05:56.367856+01:00","dependencies":[{"issue_id":"engram-0ro","depends_on_id":"engram-dxj","type":"blocks","created_at":"2026-02-14T22:57:25.38331+01:00","created_by":"daemon"}]}
{"id":"engram-2ui","title":"Obsidian-Compatible Vault Mirror","description":"Add bidirectional markdown mirror layer: Convex remains system of record, markdown vault provides human-inspectable Obsidian-compatible files.\n\n**Implementation order (dependency chain):**\nP1 Core: engram-ywx (schema) → engram-waf (format) → engram-7yr (sync engine) → engram-dxj (MCP tool)\nP1 Parallel: engram-ri0 (Convex actions, depends on ywx)\nP2 Enhancements: engram-doo (observation pipeline), engram-43e (graph+autolinker), engram-gxr (index pipeline), engram-vj6 (query tools), engram-ykh (backlinks), engram-4ul (checkpoint/wake), engram-sll (budgeted recall)\nP3 Advanced: engram-uah (file watcher), engram-8nz (auditability)\nP4 Quality: engram-0ro (validation suite)\n\n**Key corrections applied (2026-02-14):**\n- Flattened observation.* fields to observationTier/observationCompressed/observationOriginalContent (Convex compatibility)\n- Fixed index references: timestamp (not createdAt), lifecycleState (not status)\n- Added missing spec fields: confidence, importanceTier\n- Clarified ri0 vs 8nz layer boundaries (Convex actions vs MCP lib)\n\nSee specs/obsidian-mirror-plan.md and specs/clawvault-learnings.md for full details.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-14T22:55:59.277332+01:00","updated_at":"2026-02-14T23:09:21.274876+01:00"}
{"id":"engram-43e","title":"Knowledge graph index + auto-linker for wiki-links","description":"Knowledge graph index + wiki-link auto-linking:\n\n**New files:**\n1. mcp-server/src/lib/wiki-link-parser.ts:\n   - extractWikiLinks(content) → WikiLink[] — Parse [[Name]] links, return {name, startIndex, endIndex}\n   - hasWikiLink(content, entityName) → boolean — Check if entity already linked\n   - Edge cases: nested brackets (parse outer), escaped \\[[...]] (ignore), whitespace [[  Name  ]] (trim)\n\n2. mcp-server/src/lib/auto-linker.ts:\n   - autoLinkEntities(content, scopeId, convex) → string — Auto-wrap entity mentions in [[...]]\n   - Algorithm: (1) Get all entities in scope, (2) Extract existing links, (3) Sort entities by name length (longest first), (4) Replace first mention of each entity with [[Name]], (5) Skip if already linked\n   - Case-insensitive matching, word boundaries only (\\b...\\b)\n\n3. mcp-server/src/lib/graph-exporter.ts:\n   - exportGraph(convex, outputPath) → void — Generate Obsidian-compatible graph JSON\n   - Format: {nodes: [{id, label, type, group}], links: [{source, target, type}]}\n   - Include fact→entity edges (type: 'mentions') and entity→entity edges (type: rel.relationshipType)\n\n**Convex schema changes (entities table):**\n- Add backlinks array: v.array(v.object({factId: v.id('facts'), factType: v.string(), linkedAt: v.number()}))\n\n**Integration in store-fact.ts:**\n- Before storing: linkedContent = await autoLinkEntities(content, scopeId, convex)\n- After storing: Update entity backlinks for each [[Name]] found\n\n**New MCP tool (in engram-vj6):**\n- memory_export_graph — Export graph to vault/.obsidian/graph.json\n\n**Tests:** auto-linking-e2e.test.ts (store fact mentioning 'Convex' → content has [[Convex]]), graph-export-e2e.test.ts (valid Obsidian JSON)\n**Performance:** Auto-link \u003c50ms, graph export \u003c2s for 10k facts\nRef: VAULT_INTEGRATION_PLAN.md Phase 4 (sections 4.2-4.6)","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:39.209329+01:00","updated_at":"2026-02-14T23:04:00.874083+01:00","dependencies":[{"issue_id":"engram-43e","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T22:57:20.586856+01:00","created_by":"daemon"}]}
{"id":"engram-46g","title":"Install vault integration npm dependencies","description":"Install required npm packages for vault integration:\n\n**MCP server dependencies:**\n```bash\ncd mcp-server\nbun add chokidar js-yaml marked slugify\nbun add -d @types/js-yaml @types/marked\n```\n\n**Packages:**\n- chokidar ^4.0.1 — File watching for vault-sync daemon\n- js-yaml ^4.1.0 — YAML frontmatter parsing\n- marked ^15.0.4 — Markdown parsing (if needed)\n- slugify ^1.6.6 — Filename slug generation\n- @types/js-yaml ^4.0.9 — TypeScript types\n- @types/marked ^7.0.0 — TypeScript types\n\n**Verification:**\n- Run bun install to ensure lock file updated\n- Verify imports work: import yaml from 'js-yaml', import chokidar from 'chokidar'\n- No version conflicts with existing packages\n\n**This blocks:** engram-waf (needs slugify + js-yaml), engram-7yr (needs chokidar)\n\nRef: VAULT_INTEGRATION_PLAN.md Appendix B","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T23:07:22.072674+01:00","updated_at":"2026-02-14T23:07:22.072674+01:00"}
{"id":"engram-4ul","title":"Checkpoint/wake tools for context death resilience","description":"Add two new MCP tools for session continuity across context deaths:\n\n(1) memory_checkpoint: params workingOn (string), focus (optional), blocked (optional), urgent (bool). Writes to .engram/last-checkpoint.json + checkpoint history. Sets dirty-death flag. If urgent, triggers immediate wake.\n\n(2) memory_wake: detects dirty-death flag, loads checkpoint data, loads recent observations with temporal decay (today=all structural+potential, yesterday=structural+top5 potential, 2-3 days=structural only, 4-6 days=top 3 structural), builds session recap from handoffs/projects/commitments, returns bootstrap context.\n\n(3) memory_end_session should clear the dirty-death flag on clean exit.\n\nRequires observationTier field from engram-ywx (via engram-doo classification) to filter by importance tier during wake context loading.\n\nRef: specs/obsidian-mirror-plan.md §6.1-6.3, ClawVault checkpoint.ts + wake.ts pattern","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:57.086118+01:00","updated_at":"2026-02-14T23:08:40.88979+01:00","dependencies":[{"issue_id":"engram-4ul","depends_on_id":"engram-doo","type":"blocks","created_at":"2026-02-14T22:57:23.00886+01:00","created_by":"daemon"}]}
{"id":"engram-7yr","title":"Create vault-sync.ts: Convex→MD export engine","description":"Create mcp-server/src/lib/vault-writer.ts + mcp-server/src/daemons/vault-sync.ts:\n\n**vault-writer.ts:**\n- writeFactToVault(fact, vaultRoot) — Generate frontmatter + body, compute folder/filename, ensure folder exists (mkdir -p), atomic write (tempfile + rename), return {success, path, error}\n- Error handling: disk full (retry w/ backoff), permission denied (log + mark unmirrored), invalid filename (sanitize + retry)\n- Performance: \u003c500ms p95 for write\n\n**vault-sync daemon (daemons/vault-sync.ts):**\n- Poll Convex every 5s for facts with vaultPath==null (getUnmirrored query, limit 100)\n- Write files using vault-writer.ts\n- Update fact.vaultPath + vaultSyncedAt in Convex after success\n- Watch vault/ using chokidar for file changes (ignoreInitial: true)\n- On file change: trigger reconcileFromVault action (to be implemented in engram-8nz)\n- Graceful shutdown on SIGTERM/SIGINT\n- Exponential backoff on Convex connection errors\n- Logging: JSON structured logs with event, factId, latency, timestamp\n\n**Lifecycle:**\n- Starts with MCP server (bun run mcp-server/src/index.ts)\n- Restarts automatically on crash\n\n**Dependencies:** chokidar, ConvexHttpClient\n**Tests:** write-through-e2e.test.ts (store fact → file appears \u003c5s), high-volume-writes.test.ts (10k facts in 60s)\n**Performance:** Mirror lag \u003c5s p95, sync reliability 99.99%\nRef: VAULT_INTEGRATION_PLAN.md Phase 3 (sections 3.1-3.3, 3.5-3.7)","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:18.15318+01:00","updated_at":"2026-02-14T23:03:26.439202+01:00","dependencies":[{"issue_id":"engram-7yr","depends_on_id":"engram-waf","type":"blocks","created_at":"2026-02-14T22:57:18.458469+01:00","created_by":"daemon"},{"issue_id":"engram-7yr","depends_on_id":"engram-46g","type":"blocks","created_at":"2026-02-14T23:07:29.701337+01:00","created_by":"daemon"}]}
{"id":"engram-8nz","title":"Auditability: diffs, provenance metadata, edit reconciliation","description":"MCP-side auditability layer: reconciliation lib, diffs, provenance metadata. This is the MCP lib layer; the Convex-side reconciliation action is in engram-ri0.\n\n**New file: mcp-server/src/lib/vault-reconciler.ts**\n\n1. reconcileFileEdit(filePath, convex):\n   - Read file from disk, parse frontmatter + body\n   - Fetch DB fact by convexId from frontmatter\n   - Compare updatedAt timestamps\n   - If DB newer: check for conflicts using detectConflicts()\n   - Merge human edits using mergeHumanEdits()\n   - Call Convex reconcileFromVault action (engram-ri0) with merged data\n   - Return {success, conflicts[]}\n\n2. detectConflicts(dbFact, fileFact) returns ConflictField[]:\n   - Check HUMAN_EDITABLE_FIELDS for divergent changes\n   - Return array of {field, dbValue, fileValue}\n\n3. writeConflictFile(filePath, dbFact, fileFact, conflicts):\n   - Create {filename}.conflict.md in vault/.meta/conflicts/\n   - Show both values side-by-side with resolution instructions\n\n**Provenance tracking:**\n- All markdown files include provenance footer: agent, timestamp, accessedCount, sessionId\n- Frontmatter includes: source (session/import/migration), sessionId\n\n**New MCP tool: memory_vault_diff**\n- Show pending changes between vault and Convex before sync\n\n**Tests:** reconcile-e2e.test.ts, conflict-e2e.test.ts, roundtrip.test.ts\n**Performance:** Reconcile \u003c200ms p95, zero data loss over 10k ops\nRef: specs/obsidian-mirror-plan.md §2.4","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-14T22:57:07.001323+01:00","updated_at":"2026-02-14T23:08:11.83238+01:00","dependencies":[{"issue_id":"engram-8nz","depends_on_id":"engram-waf","type":"blocks","created_at":"2026-02-14T23:08:15.003764+01:00","created_by":"daemon"},{"issue_id":"engram-8nz","depends_on_id":"engram-ri0","type":"blocks","created_at":"2026-02-14T23:08:15.449398+01:00","created_by":"daemon"}]}
{"id":"engram-8ro","title":"Phase 5: Local Sync — LanceDB daemon, offline vector search fallback","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T10:02:08.462183+01:00","updated_at":"2026-02-12T10:06:05.733398+01:00","closed_at":"2026-02-12T10:06:05.733398+01:00","close_reason":"Completed"}
{"id":"engram-doo","title":"Observation pipeline: scored format + importance tiers","description":"Priority-tiered observation pipeline with LLM classification:\n\n**New Convex actions:**\n1. convex/actions/classifyObservation.ts:\n   - Use Claude Haiku for fast classification (\u003c2s)\n   - Prompt: Classify into CRITICAL (decisions/commitments/failures), NOTABLE (insights/learnings), BACKGROUND (routine/minor)\n   - Map tier to priority: CRITICAL→0, NOTABLE→1, BACKGROUND→4\n   - Update fact with priority + observationTier (flat field, see engram-ywx)\n   - If P0-P2: Trigger full enrichment (embeddings, entities, importance)\n   - If P3-P4: Trigger background compression\n\n2. convex/actions/compressBackground.ts:\n   - Generate 1-sentence summary (max 20 words) using Haiku\n   - Store original in observationOriginalContent (flat field)\n   - Set observationCompressed = true (flat field)\n   - Set lifecycleState = \"archived\" (skip indexing/recall)\n\n**MCP tool change (mcp-server/src/tools/observe.ts):**\n- Store observation with lifecycleState=\"active\", trigger classifyObservation action (non-blocking)\n- Agent gets immediate response, classification happens async\n\n**Recall filtering (mcp-server/src/tools/recall.ts):**\n- Add priority filter: default exclude P3-P4 unless explicit priorityFilter arg\n\n**Schema fields (in engram-ywx):**\n- observationTier: v.optional(v.string()) — \"critical\"|\"notable\"|\"background\"\n- observationCompressed: v.optional(v.boolean())\n- observationOriginalContent: v.optional(v.string()) — Content before compression\n\nNOTE: All observation.* fields from original plan are flattened for Convex compatibility.\n\n**Tests:** observation-compression-e2e.test.ts, classification-latency.test.ts (\u003c2s)\n**Performance:** Classification \u003c2s, compression \u003c1s, observation noise reduction \u003e80%\nRef: specs/obsidian-mirror-plan.md §3.1-3.3","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:32.190346+01:00","updated_at":"2026-02-14T23:08:27.902502+01:00","dependencies":[{"issue_id":"engram-doo","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T22:57:19.817066+01:00","created_by":"daemon"}]}
{"id":"engram-dxj","title":"Add MCP tool: memory_vault_sync","description":"Add MCP tool: memory_vault_sync for manual vault synchronization:\n\n**New tool: memory_vault_sync (mcp-server/src/tools/vault-sync.ts)**\n\nParameters:\n- direction: 'export' | 'import' | 'both' (default: 'both')\n- force: boolean (default: false) — Force re-export even if vaultPath exists\n- dryRun: boolean (default: false) — Show what would be synced without executing\n\n**Export mode (Convex → Vault):**\n- Fetch all facts with vaultPath == null OR force == true\n- Export to markdown using vault-format.ts\n- Update vaultPath + vaultSyncedAt in Convex\n- Return: {exported: count, skipped: count, errors: []}\n\n**Import mode (Vault → Convex):**\n- Scan vault/ for .md files\n- Parse frontmatter, match by ID\n- Reconcile changes using vault-reconciler.ts\n- Update DB with human edits\n- Return: {imported: count, conflicts: count, errors: []}\n\n**Both mode:**\n- Run export first, then import\n- Return combined stats\n\n**Use cases:**\n- Initial vault population after system install\n- Manual sync after vault-sync daemon crashes\n- Batch import after human edits in Obsidian\n- Dry run to preview sync changes\n\n**Integration:**\n- Uses vault-writer.ts (from engram-7yr)\n- Uses vault-reconciler.ts (from engram-8nz)\n- Uses vault-format.ts (from engram-waf)\n\n**Tests:** vault-sync-e2e.test.ts (export/import/both modes work), dry-run.test.ts (no actual changes)\n**Performance:** Export 1000 facts \u003c10s, import 1000 files \u003c15s\nRef: VAULT_INTEGRATION_PLAN.md Phase 3.2, Phase 3.4","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:26.618882+01:00","updated_at":"2026-02-14T23:06:30.561569+01:00","dependencies":[{"issue_id":"engram-dxj","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T22:57:19.207572+01:00","created_by":"daemon"}]}
{"id":"engram-gxr","title":"Vault index pipeline implementation + cron trigger","description":"Vault index pipeline for index-first retrieval:\n\n**New file: mcp-server/src/lib/vault-indexer.ts**\nImplements index generation:\n\n1. generateIndices(convex, vaultRoot) — Master function, creates:\n   - vault/.index/vault-index.md — Master TOC (recent + by-type sections)\n   - vault/.index/by-priority.md — Facts grouped by priority tier (0-4)\n   - vault/.index/by-entity.md — Facts grouped by entity mentions\n\n2. generateMasterIndex(facts, vaultRoot):\n   - Recent section: Last 7 days, sorted by date desc\n   - By Type section: Group by fact.type, sort by importance desc, show top 10 per type\n   - Format: '- [date] **Type**: title → path [importance: X.XX]'\n\n3. generatePriorityIndex(facts, vaultRoot):\n   - 5 sections: Critical (P0), High (P1), Medium (P2), Low (P3), Backlog (P4)\n   - Sort within tier by importance desc, show top 20 per tier\n\n4. generateEntityIndex(facts, vaultRoot):\n   - Build mention count map from wiki-links\n   - Sort entities by mention count desc\n   - For each entity: show top 10 facts by importance\n\n**Recall tool enhancement (mcp-server/src/tools/recall.ts):**\n- searchIndex(query, filters) — Scan relevant index file, extract matching paths, compute confidence\n- Index-first strategy: If 5+ matches AND confidence \u003e0.7 → return index results, else fallback to semantic\n- Confidence = (keyword coverage) × (match density)\n\n**Convex cron (convex/crons/regenerateIndices.ts):**\n- Schedule: */5 * * * * (every 5 minutes)\n- Action: Signal MCP daemon to regenerate indices (webhook or polling flag)\n\n**Tests:** index-generation.test.ts (verify format), index-first-e2e.test.ts (query → index scan → results)\n**Performance:** Index scan \u003c100ms p95, index hit rate \u003e65%, relevance@5 \u003e0.85\nRef: VAULT_INTEGRATION_PLAN.md Phase 5 (sections 5.2-5.7)","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:26.85327+01:00","updated_at":"2026-02-14T23:04:22.987481+01:00","dependencies":[{"issue_id":"engram-gxr","depends_on_id":"engram-7yr","type":"blocks","created_at":"2026-02-14T23:01:38.333371+01:00","created_by":"daemon"},{"issue_id":"engram-gxr","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:44.162538+01:00","created_by":"daemon"}]}
{"id":"engram-h09","title":"Phase 3: Async Enrichment — Cohere Embed 4, entity extraction, synthesis, importance","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:50:59.367012+01:00","updated_at":"2026-02-12T10:06:05.440978+01:00","closed_at":"2026-02-12T10:06:05.440978+01:00","close_reason":"Completed"}
{"id":"engram-ri0","title":"Convex mirror integration: actions + facts hooks","description":"Convex-side mirror integration (actions + facts hooks). This is the Convex action layer; the MCP-side reconciliation lib is in engram-8nz.\n\n**New Convex actions:**\n1. convex/actions/mirrorToVault.ts — Signal action triggered after storeFact/updateFact. Sets flag for vault-sync daemon to pick up. Simple implementation: log event, daemon polls.\n2. convex/actions/reconcileFromVault.ts — Handle file edits from vault (called by MCP vault-reconciler in engram-8nz). Three-way merge logic:\n   - Fetch DB fact by ID\n   - Compare updatedAt timestamps\n   - Field-level merge: HUMAN_FIELDS (content, tags, entities, priority, type) vs MACHINE_FIELDS (embedding, importance, decayFactor, synthesizedContext)\n   - If conflict detected: return conflict info for MCP layer to create .conflict file\n   - Update DB with merged values\n   - Return {success, conflicts[]}\n\n**Convex functions/facts.ts changes:**\n- Add mutation updateVaultPath(id, vaultPath) — Update fact.vaultPath after mirror\n- Add query getUnmirrored(limit) — Return facts where vaultPath == null, ordered by timestamp desc\n- Modify storeFact — Call mirrorToVault action after insert (non-blocking)\n\n**Field classification constants:**\n- HUMAN_FIELDS = [\"content\", \"tags\", \"entities\", \"priority\", \"type\"]\n- MACHINE_FIELDS = [\"embedding\", \"importance\", \"decayFactor\", \"synthesizedContext\"]\n- IMMUTABLE_FIELDS = [\"_id\", \"timestamp\", \"createdBy\", \"scopeId\"]\n\n**Tests:** reconcile-e2e.test.ts, conflict-e2e.test.ts\n**Performance:** Reconcile \u003c200ms p95\nRef: specs/obsidian-mirror-plan.md §2.2-2.4","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T23:00:27.123529+01:00","updated_at":"2026-02-14T23:07:57.851847+01:00","dependencies":[{"issue_id":"engram-ri0","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T23:01:38.347058+01:00","created_by":"daemon"}]}
{"id":"engram-sll","title":"Context-budgeted recall with profiles","description":"Context-budgeted recall with explainability:\n\n**New file: mcp-server/src/lib/budget-aware-loader.ts**\n\n1. loadBudgetAwareContext(query, budget, convex) returns LoadedContext with facts, entities, themes, tokenUsage, and explainability array\n   - Budget allocation tiers: Critical 40%, Notable 40%, Background 10%, Entities 10%\n   - Fetch candidates via semantic search (limit 100, over-fetch then filter)\n   - Sort by: priority ASC then importanceScore DESC then timestamp DESC (deterministic)\n   - Fill tiers until budget exhausted\n   - Token estimation: chars/4 (rough estimate)\n\n2. detectQueryIntent(query) returns BudgetConfig based on keywords:\n   - decision/commit queries: 80% Critical, 20% Notable\n   - observation/recent queries: 10% Critical, 30% Notable, 60% Background\n   - Default: 40/40/10/10\n\n3. getInclusionReason(fact) explains why fact was loaded:\n   - Priority 0: Critical decision/commitment\n   - importanceScore \u003e0.8: High importance\n   - Created \u003c24h: Recent creation\n   - Default: Semantic relevance\n\n**Context profiles (from spec §5.1):**\n- Add profile parameter to memory_get_context: \"default\"|\"planning\"|\"incident\"|\"handoff\"\n- Each profile has different source ordering (structural, daily, search, graph, potential, contextual)\n\n**MCP tool enhancement (mcp-server/src/tools/get-context.ts):**\n- Add tokenBudget parameter (default 4000 from spec §5.2)\n- Add profile parameter (default \"default\")\n- Replace simple loader with loadBudgetAwareContext\n- Return facts, entities, themes, tokenUsage by tier, explainability array, truncated flag\n\n**Tests:** budget-aware-context-e2e.test.ts, budget-aware-latency.test.ts (\u003c200ms)\n**Performance:** Context load \u003c200ms, token efficiency 30% better, overflow rate \u003c2%\nRef: specs/obsidian-mirror-plan.md §5.1-5.3","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T22:56:50.889612+01:00","updated_at":"2026-02-14T23:09:07.804239+01:00","dependencies":[{"issue_id":"engram-sll","depends_on_id":"engram-doo","type":"blocks","created_at":"2026-02-14T22:57:21.461965+01:00","created_by":"daemon"},{"issue_id":"engram-sll","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T22:57:22.260754+01:00","created_by":"daemon"}]}
{"id":"engram-u51","title":"Engram Phase 1: Foundation — Convex Backend Setup","description":"# Engram Phase 1: Foundation\n\n## Background\nEngram is a unified multi-agent memory system for OpenClaw agents. It provides a shared memory layer where agents store atomic facts, recall context via semantic search, and share knowledge across devices and sessions. Local-first via LanceDB, cloud-synced through Convex, multimodal embeddings via Cohere Embed 4.\n\n## What This Epic Covers\nPhase 1 establishes the foundational data layer in Convex that every subsequent phase builds on:\n- Initialize Convex project\n- Deploy full 10-table schema (all optional future-phase fields included)\n- Implement CRUD mutations/queries for all 10 tables\n- Full-text search on facts with scope/type/agent filtering\n- Scope-based write permission enforcement on storeFact\n- Seed script to populate initial entities and default scopes\n\n## Why Full Schema From Day 1\nThe repo-research agent identified 17 schema discrepancies between PLAN.md (full) and the detailed plan (simplified). Decision: deploy PLAN.md's full schema with all future-phase fields as v.optional(). Convex schema changes require migrations; adding fields later is friction. Optional fields cost nothing until populated. Deploy once, never migrate schema.\n\n## Key Technical Decisions (Locked)\n- Backend: Convex (realtime, native vector search, scheduled functions, free tier)\n- Embeddings: Cohere Embed 4 (1024-dim, multimodal) — NOT OpenAI\n- MCP SDK: @modelcontextprotocol/sdk v1.x (Phase 2, not Phase 1)\n- Access control: Scope-based (NOT per-fact ACLs)\n- Memory lifecycle: 5-state machine (active → dormant → merged → archived → pruned)\n- Decay: Differential by fact type + emotional weight\n- Use lifecycleState (5 states) NOT status (3 states)\n\n## Phase 1 Scope Boundary\nIN SCOPE: Convex project init, schema, CRUD, full-text search, seed script, write permissions\nOUT OF SCOPE: MCP server (Phase 2), embeddings/enrichment (Phase 3), multi-agent (Phase 4), LanceDB sync (Phase 5), migration (Phase 6)\n\n## Success Criteria\n- npx convex dev runs successfully with all 10 tables visible in dashboard\n- Can insert a fact via storeFact mutation with scope write permission check\n- Full-text search on facts.content returns results filtered by scopeId, factType, createdBy\n- All 10 tables have basic CRUD operations\n- Seed script populates initial entities and default scopes\n- Write to scope with writePolicy: \"members\" fails for non-members\n- TypeScript strict mode, no any types in function args/returns\n\n## References\n- PLAN.md — Full schema (lines 89-289), Phase 1 checklist (lines 490-496)\n- docs/plans/2026-02-11-feat-engram-phase1-foundation-plan.md — Detailed Phase 1 plan\n- docs/research/tech-stack-best-practices.md — Convex patterns (1297 lines)\n- docs/INSTITUTIONAL_LEARNINGS.md — 8 critical implementation patterns","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-11T22:03:49.903178+01:00","updated_at":"2026-02-12T09:42:34.927436+01:00","closed_at":"2026-02-12T09:42:34.927436+01:00","close_reason":"Closed"}
{"id":"engram-u51.1","title":"Initialize Convex project","description":"# Initialize Convex Project\n\n## What\nRun npx create-convex in the Engram repo root to set up the Convex backend project. This creates the convex/ directory structure that all subsequent tasks depend on.\n\n## Why\nConvex is the cloud backend for Engram. It provides the schema DSL (defineSchema, defineTable, v validators), the function runtime (query, mutation, action), native vector search, scheduled functions (crons), and the ConvexHttpClient for external access. Without this initialization, no other Phase 1 work can proceed.\n\n## Steps\n1. Run npx create-convex in /Volumes/Main SSD/Developer/engram\n2. Select \"create a new project\" when prompted\n3. Verify convex/ directory created with:\n   - _generated/ (auto-generated types — commit per Convex best practices)\n   - tsconfig.json (Convex-specific TypeScript config)\n4. Verify root package.json updated with convex dependency (^1.17.0)\n5. Run npx convex dev to confirm project compiles with empty schema\n6. Update .gitignore if needed (Convex may add entries; convex/_generated/ should be committed)\n\n## Technical Notes\n- The current package.json only has beautiful-mermaid as dependency\n- Node.js 22+ and TypeScript 5.7+ are prerequisites\n- Convex free tier is sufficient for development\n- Environment variable CONVEX_URL will be obtained from this step\n\n## Acceptance Criteria\n- [ ] convex/ directory exists with _generated/ and tsconfig.json\n- [ ] package.json has convex ^1.17.0 in dependencies\n- [ ] npx convex dev compiles without errors (empty schema OK)\n- [ ] CONVEX_URL environment variable available (from .env.local or Convex dashboard)\n\n## Gotchas\n- npx create-convex may prompt for auth — need Convex account (free tier)\n- The generated convex/_generated/ directory SHOULD be committed (Convex convention)\n- Existing .gitignore already has .env and .env.local entries (good)\n\n## Estimate\n15 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:04:07.072193+01:00","updated_at":"2026-02-11T22:25:05.646734+01:00","closed_at":"2026-02-11T22:25:05.646755+01:00","dependencies":[{"issue_id":"engram-u51.1","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:07.074429+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.10","title":"Implement themes CRUD for hierarchical memory","description":"# Implement Themes CRUD\n\n## What\nCreate convex/functions/themes.ts for the themes table. Themes are thematic clusters of related facts — the EverMemOS MemScenes pattern for hierarchical memory.\n\n## Why\nThemes provide a higher-level view of memory. Instead of searching through hundreds of individual facts, agents can retrieve theme summaries. The weekly consolidation cron (Phase 6) will automatically group related facts into themes. Themes have their own embeddings for vector search.\n\n## Schema (from PLAN.md)\n- name: string\n- description: string\n- factIds: Id\u003c\"facts\"\u003e[] (facts in this theme)\n- entityIds: Id\u003c\"entities\"\u003e[] (related entities)\n- scopeId: Id\u003c\"memory_scopes\"\u003e\n- importance: float64\n- lastUpdated: number\n- embedding: float64[]? (1024-dim, for vector search on themes)\n\n## Functions to Implement\n\n### Mutations\n1. create(name, description, factIds, entityIds, scopeId, importance?)\n2. update(themeId, description?, factIds?, entityIds?, importance?)\n   - Update lastUpdated to Date.now()\n3. addFact(themeId, factId) — append to factIds (convenience)\n\n### Queries\n4. get(themeId)\n5. getByScope(scopeId, limit?) — using by_scope index\n6. searchThemes(query) — could use a searchIndex if added, or filter by name\n\n## Acceptance Criteria\n- [ ] Can create themes linked to scopes, facts, and entities\n- [ ] Can update theme description and add facts\n- [ ] getByScope returns themes for a given scope\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:52.954648+01:00","updated_at":"2026-02-11T22:25:07.618047+01:00","closed_at":"2026-02-11T22:25:07.61805+01:00","dependencies":[{"issue_id":"engram-u51.10","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:52.955901+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.10","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:52.957741+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.11","title":"Implement sync_log CRUD for LanceDB sync tracking","description":"# Implement Sync Log CRUD\n\n## What\nCreate convex/functions/sync.ts for the sync_log table. Tracks per-node LanceDB sync status for Phase 5.\n\n## Why\nEach device (Mac Mini, MacBook Air, MacBook Pro) runs its own LanceDB instance. The sync_log tracks what each node has synced, enabling differential sync (only pull facts since last sync). Phase 1 creates the CRUD; Phase 5 will use it for the actual sync daemon.\n\n## Schema (from PLAN.md)\n- nodeId: string — device identifier\n- lastSyncTimestamp: number — when this node last synced\n- factsSynced: number — total facts synced to this node\n- status: string — ok|error|syncing\n\n## Functions to Implement\n\n### Mutations\n1. updateSyncLog(nodeId, lastSyncTimestamp, factsSynced, status)\n   - Upsert by nodeId (create or update)\n\n### Queries\n2. getSyncStatus(nodeId) — using by_node index\n3. getFactsSince(timestamp, scopeId?) — internalQuery\n   - Return facts created/updated after timestamp\n   - Filter by scope if provided\n   - Used by sync daemon in Phase 5\n\n## Acceptance Criteria\n- [ ] Can create/update sync log entries\n- [ ] getSyncStatus returns correct status for a node\n- [ ] getFactsSince returns facts after a given timestamp\n\n## Estimate\n15 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:07:04.289418+01:00","updated_at":"2026-02-11T22:25:07.810836+01:00","closed_at":"2026-02-11T22:25:07.810844+01:00","dependencies":[{"issue_id":"engram-u51.11","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:04.290514+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.11","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:07:04.29189+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.12","title":"Write seed script to populate initial entities and scopes","description":"# Write Seed Script\n\n## What\nCreate scripts/seed.ts to populate the Convex database with initial entities, default scopes, and sample facts. Uses ConvexHttpClient to call mutations from outside the Convex runtime.\n\n## Why\nThe seed script bootstraps Engram with a useful starting state:\n- Default scopes (global, private-indy) for immediate use\n- Core entities (Ryan, Indy, OpenClaw, Engram, Convex, LanceDB, Cohere) with relationships\n- Sample facts to verify full-text search and CRUD work end-to-end\n- Provides a repeatable setup for development and testing\n\n## Seed Data\n\n### Default Scopes\n1. global — readPolicy: \"all\", writePolicy: \"all\", description: \"Shared knowledge base accessible to all agents\"\n2. private-indy — readPolicy: \"members\", writePolicy: \"members\", members: [\"indy\"], description: \"Indy's private memory space\"\n\n### Initial Entities\n| entityId | name | type | relationships |\n|----------|------|------|---------------|\n| entity-ryan | Ryan | person | created_by: entity-openclaw, works_with: entity-indy |\n| entity-indy | Indy | person | works_with: entity-ryan, part_of: entity-openclaw |\n| entity-openclaw | OpenClaw | project | created_by: entity-ryan |\n| entity-engram | Engram | project | part_of: entity-openclaw, depends_on: entity-convex, depends_on: entity-lancedb |\n| entity-convex | Convex | tool | related_to: entity-engram |\n| entity-lancedb | LanceDB | tool | related_to: entity-engram |\n| entity-cohere | Cohere | tool | related_to: entity-engram |\n\n### Sample Facts (3-5 facts for testing)\n- \"Engram uses Cohere Embed 4 for 1024-dim multimodal embeddings\" (factType: decision, scope: global)\n- \"Convex vector search is only available in actions, not queries\" (factType: learning, scope: global)\n- \"Ryan is the creator of OpenClaw and its agent ecosystem\" (factType: observation, scope: global)\n\n## Implementation Pattern\n\n```typescript\n// scripts/seed.ts\nimport { ConvexHttpClient } from \"convex/browser\";\nimport { api } from \"../convex/_generated/api\";\n\nconst client = new ConvexHttpClient(process.env.CONVEX_URL!);\n\nasync function seed() {\n  console.error(\"[seed] Starting...\");\n\n  // 1. Create scopes first (facts need scopeIds)\n  const globalScope = await client.mutation(api.functions.scopes.createScope, {\n    name: \"global\",\n    description: \"Shared knowledge base\",\n    members: [\"indy\"],\n    readPolicy: \"all\",\n    writePolicy: \"all\",\n  });\n\n  // 2. Register agent\n  await client.mutation(api.functions.agents.register, {\n    agentId: \"indy\",\n    name: \"Indy\",\n    capabilities: [\"memory\", \"code\", \"research\"],\n    defaultScope: \"private\",\n  });\n\n  // 3. Create entities\n  for (const entity of entities) {\n    await client.mutation(api.functions.entities.upsert, entity);\n  }\n\n  // 4. Store sample facts\n  for (const fact of sampleFacts) {\n    await client.mutation(api.functions.facts.storeFact, {\n      ...fact,\n      scopeId: globalScope,\n      createdBy: \"indy\",\n    });\n  }\n\n  console.error(\"[seed] Done!\");\n}\n\nseed().catch(console.error);\n```\n\n## Technical Notes\n- Use ConvexHttpClient (not internal functions) — seed runs OUTSIDE Convex runtime\n- Use console.error for all logging (stdout hygiene habit from MCP patterns)\n- Use process.env.CONVEX_URL for Convex connection\n- Run with: npx tsx scripts/seed.ts (or npx convex run scripts/seed if using Convex runner)\n- Batch pattern: Could use a single batch mutation for entities, but individual calls are fine for seed data (~10 items)\n- Make idempotent: upsert for entities, check-before-create for scopes\n\n## Acceptance Criteria\n- [ ] scripts/seed.ts exists and runs without errors\n- [ ] Creates global and private-indy scopes\n- [ ] Creates 7 initial entities with relationships\n- [ ] Stores 3+ sample facts in global scope\n- [ ] Facts are searchable via full-text search after seeding\n- [ ] Script is idempotent (running twice doesn't create duplicates)\n- [ ] All logging goes to stderr\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:07:29.875278+01:00","updated_at":"2026-02-11T22:25:07.967342+01:00","closed_at":"2026-02-11T22:25:07.967345+01:00","dependencies":[{"issue_id":"engram-u51.12","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:29.876065+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.3","type":"blocks","created_at":"2026-02-11T22:07:29.877179+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.4","type":"blocks","created_at":"2026-02-11T22:07:29.878235+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.5","type":"blocks","created_at":"2026-02-11T22:07:29.879421+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.12","depends_on_id":"engram-u51.6","type":"blocks","created_at":"2026-02-11T22:07:29.882011+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.13","title":"End-to-end verification and testing","description":"# End-to-End Verification\n\n## What\nVerify that all Phase 1 deliverables work correctly together. This is the final quality gate before Phase 2 can begin.\n\n## Why\nPhase 2 (MCP Server) depends entirely on Phase 1's Convex functions working correctly. Every MCP tool call ultimately hits a Convex mutation or query. If the foundation is broken, everything built on it will be broken.\n\n## Verification Checklist\n\n### Schema Verification\n- [ ] npx convex dev compiles without errors\n- [ ] Convex dashboard shows all 10 tables: facts, entities, conversations, sessions, agents, memory_scopes, signals, themes, sync_log\n- [ ] Each table has correct indexes visible in dashboard\n- [ ] vector_search index defined on facts (dimensions: 1024)\n- [ ] theme_search index defined on themes (dimensions: 1024)\n\n### CRUD Round-Trip Tests (via Convex dashboard or convex functions CLI)\n- [ ] Create scope → query scope → add member → verify\n- [ ] Register agent → query agent → update lastSeen → verify\n- [ ] Store fact (with scope write check) → get fact by ID → verify all fields\n- [ ] Store fact to unauthorized scope → verify rejection\n- [ ] Create entity → add relationship → query by entityId → verify\n- [ ] Create session → add conversation → link fact to conversation → verify chain\n- [ ] Record signal on fact → query signals by fact → verify\n- [ ] Create theme → add facts → query by scope → verify\n\n### Full-Text Search Tests\n- [ ] Search \"Cohere\" → returns fact about embeddings\n- [ ] Search \"Convex\" with factType filter → returns only matching type\n- [ ] Search with scopeId filter → returns only facts in that scope\n- [ ] Search with createdBy filter → returns only facts by that agent\n- [ ] Empty search → returns empty array (no crash)\n\n### Write Permission Tests\n- [ ] Agent in scope.members can write to scope with writePolicy: \"members\"\n- [ ] Agent NOT in scope.members is rejected for writePolicy: \"members\"\n- [ ] Any agent can write to scope with writePolicy: \"all\"\n- [ ] Only creator can write to scope with writePolicy: \"creator\"\n\n### Seed Script Verification\n- [ ] Run scripts/seed.ts → no errors\n- [ ] Run scripts/seed.ts AGAIN → no duplicates (idempotent)\n- [ ] Query entities → 7 entities with correct relationships\n- [ ] Query scopes → global and private-indy exist\n- [ ] Search facts → seed facts are searchable\n\n### TypeScript Quality\n- [ ] No any types in function args/returns\n- [ ] TypeScript strict mode enabled in convex/tsconfig.json\n- [ ] All Convex validators use v.* types\n\n## How to Test\n1. npx convex dev — verify compile\n2. npx tsx scripts/seed.ts — run seed\n3. Use Convex dashboard to inspect tables and run queries\n4. Alternatively, use convex CLI: npx convex run functions/facts:searchFacts '{\"query\": \"Cohere\"}'\n\n## Phase 1 Complete When\nALL of the above checks pass. This unblocks Phase 2 (MCP Server).\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:07:50.19959+01:00","updated_at":"2026-02-12T09:42:34.780978+01:00","closed_at":"2026-02-12T09:42:34.780991+01:00","dependencies":[{"issue_id":"engram-u51.13","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:07:50.200464+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.4","type":"blocks","created_at":"2026-02-11T22:07:50.201628+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.5","type":"blocks","created_at":"2026-02-11T22:07:50.202672+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.6","type":"blocks","created_at":"2026-02-11T22:07:50.203805+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.7","type":"blocks","created_at":"2026-02-11T22:07:50.204824+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.8","type":"blocks","created_at":"2026-02-11T22:07:50.205908+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.9","type":"blocks","created_at":"2026-02-11T22:07:50.207039+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.10","type":"blocks","created_at":"2026-02-11T22:07:50.208045+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.11","type":"blocks","created_at":"2026-02-11T22:07:50.209063+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.13","depends_on_id":"engram-u51.12","type":"blocks","created_at":"2026-02-11T22:07:50.210063+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.2","title":"Define complete 10-table schema in convex/schema.ts","description":"# Define Complete 10-Table Schema\n\n## What\nCreate convex/schema.ts with ALL 10 tables from PLAN.md (lines 89-289), including all optional future-phase fields. This is the single most important file in Phase 1 — it defines the entire data model.\n\n## Why\nUsing the full PLAN.md schema from day 1 prevents costly migrations when later phases add lifecycle management, emotional context, temporal links, etc. Convex schema changes require explicit migrations. Optional fields (v.optional()) cost nothing until populated. Deploy once, never migrate schema.\n\n## Schema Decision: Full vs Simplified\nThe repo-research agent found 17 schema discrepancies between PLAN.md and the detailed plan. Key decisions:\n- Use lifecycleState (5 states: active|dormant|merged|archived|pruned), NOT status (3 states)\n- Include factualSummary (SimpleMem compressed representation)\n- Include updatedAt (needed for sync tracking in Phase 5)\n- Include outcomeScore (MemRL learned utility — Phase 4+)\n- Include contributingAgents (collaborative memory provenance — Phase 4+)\n- Include emotionalContext + emotionalWeight (GIZIN emotional memory — Phase 3+)\n- Include temporalLinks (MAGMA multi-graph pattern — Phase 3+)\n- Include forgetScore, mergedInto, consolidatedFrom, supersededBy (lifecycle — Phase 3+)\n- Include conversations.threadFacts (facts-to-conversations linking)\n- Include sessions.conversationIds (session-conversation links)\n- Include agents.telos (PAI purpose/goal)\n- Include memory_scopes.memoryPolicy + idealStateCriteria (ALMA + PAI)\n\n## Tables to Define\n\n### 1. facts (26 fields, 5 indexes + 1 searchIndex + 1 vectorIndex)\nThe core memory unit. Stores atomic facts with embeddings, importance scores, lifecycle state, emotional context, temporal links, and scope.\n- Core fields: content, timestamp, source, entityIds, relevanceScore, accessedCount, importanceScore, createdBy, scopeId, tags, factType, embedding\n- Lifecycle: lifecycleState, mergedInto, consolidatedFrom, supersededBy, forgetScore\n- Emotional: emotionalContext, emotionalWeight\n- Multi-graph: temporalLinks (array of {targetFactId, relation, confidence})\n- Research-informed: factualSummary, updatedAt, outcomeScore, contributingAgents\n- References: conversationId\n- Indexes: by_scope, by_agent, by_type, by_importance, by_lifecycle\n- searchIndex: search_content (field: content, filters: scopeId, factType, createdBy)\n- vectorIndex: vector_search (field: embedding, dimensions: 1024, filters: scopeId)\n\n### 2. entities (name, type, relationships graph, 4 indexes)\n### 3. conversations (sessionId, participants, threadFacts, handoffs, 2 indexes)\n### 4. sessions (agentId, conversationIds, factCount, 2 indexes)\n### 5. agents (agentId, name, capabilities, telos, settings, 1 index)\n### 6. memory_scopes (name, members, policies, ISC, 1 index)\n### 7. signals (factId, agentId, signalType, value, 3 indexes)\n### 8. themes (name, factIds, entityIds, scopeId, embedding, 2 indexes + 1 vectorIndex)\n### 9. sync_log (nodeId, lastSyncTimestamp, status, 1 index)\n\n## Critical Constraints\n- vectorIndex dimensions MUST be 1024 (Cohere Embed 4 output dimension)\n- vectorIndex filterFields only support equality filters via q.eq()\n- searchIndex filterFields support equality filters for pre-filtering\n- All future-phase fields must be v.optional()\n- factType is a string union: decision|observation|plan|error|insight|correction|steering_rule|learning|session_summary\n- lifecycleState string union: active|dormant|merged|archived|pruned\n\n## Source of Truth\nCopy schema definitions EXACTLY from PLAN.md lines 89-289. The schema in the detailed plan (docs/plans/2026-02-11-feat-engram-unified-memory-system-plan.md lines 93-242) is the SIMPLIFIED version — do NOT use it.\n\n## Acceptance Criteria\n- [ ] convex/schema.ts defines all 10 tables\n- [ ] facts table has all 26 fields (most as v.optional())\n- [ ] All indexes defined (5 regular + 1 search + 1 vector on facts, plus others)\n- [ ] vectorIndex dimensions set to 1024\n- [ ] npx convex dev compiles without schema errors\n- [ ] Convex dashboard shows all 10 tables with correct structure\n\n## Estimate\n45 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:04:36.166167+01:00","updated_at":"2026-02-11T22:25:05.787684+01:00","closed_at":"2026-02-11T22:25:05.787686+01:00","dependencies":[{"issue_id":"engram-u51.2","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:36.166973+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.2","depends_on_id":"engram-u51.1","type":"blocks","created_at":"2026-02-11T22:04:36.168035+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.3","title":"Implement memory_scopes CRUD with write policy enforcement","description":"# Implement Memory Scopes CRUD\n\n## What\nCreate convex/functions/scopes.ts with full CRUD operations for the memory_scopes table, including the critical checkWriteAccess helper used by storeFact. This task must be completed BEFORE facts CRUD because storeFact depends on scope write permission enforcement.\n\n## Why\nScopes are the access control mechanism for Engram. Every fact belongs to a scope. Scopes define who can read and write. The storeFact mutation must check scope writePolicy before inserting — this is a PLAN.md Phase 1 requirement that was missing from the detailed plan.\n\nScope types:\n- private-{agentId}: Only that agent can read/write\n- team-{name}: Team members can read/write\n- project-{name}: Project-scoped with member lists\n- global: Everyone can read/write (public knowledge base)\n\n## Functions to Implement\n\n### Mutations\n1. createScope(name, description, members, readPolicy, writePolicy, retentionDays?)\n   - Validate name uniqueness via by_name index\n   - Default readPolicy: \"members\", writePolicy: \"members\"\n   - Return scope ID\n\n2. addMember(scopeId, agentId)\n   - Append to members array if not already present\n   - idempotent\n\n3. removeMember(scopeId, agentId)\n   - Filter from members array\n   - Error if agent is last member (can't have empty scope)\n\n### Queries\n4. getScope(scopeId) — by Convex _id\n5. getScopeByName(name) — using by_name index\n6. getPermittedScopes(agentId) — return all scopes where agentId is in members OR readPolicy is \"all\"\n\n### Internal Helper (exported as internalQuery)\n7. checkWriteAccess(scopeId, agentId) — returns boolean\n   - If writePolicy === \"all\": return true\n   - If writePolicy === \"members\": return members.includes(agentId)\n   - If writePolicy === \"creator\": return members[0] === agentId (first member is creator)\n\n## Write Policy Logic\n| writePolicy | Who Can Write |\n|-------------|---------------|\n| \"all\" | Any agent |\n| \"members\" | Only agents in scope.members array |\n| \"creator\" | Only first member (scope creator) |\n\n## Technical Notes\n- Use Convex v validators for all args\n- Use shared helper pattern: export both public query and internalQuery versions\n- getPermittedScopes needs to check both membership AND readPolicy === \"all\"\n- For Phase 1, no auth beyond agent ID trust boundary\n\n## Acceptance Criteria\n- [ ] Can create a new scope with name, description, members, policies\n- [ ] Can add/remove members from a scope\n- [ ] getPermittedScopes returns correct scopes for an agent\n- [ ] checkWriteAccess correctly enforces writePolicy for \"all\", \"members\", \"creator\"\n- [ ] Duplicate scope names are rejected\n- [ ] Cannot remove last member from a scope\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:04:55.227542+01:00","updated_at":"2026-02-11T22:25:05.911549+01:00","closed_at":"2026-02-11T22:25:05.911551+01:00","dependencies":[{"issue_id":"engram-u51.3","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:04:55.228438+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.3","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:04:55.229555+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.4","title":"Implement facts CRUD with write permission and full-text search","description":"# Implement Facts CRUD with Write Permission \u0026 Full-Text Search\n\n## What\nCreate convex/functions/facts.ts — the most important function file. Implements storeFact (with scope write permission check), read queries, full-text search, and access tracking. This is the core memory primitive that all MCP tools will use.\n\n## Why\nFacts are the atomic memory units in Engram. Every memory_store_fact, memory_recall, memory_search MCP tool call ultimately hits these functions. Getting storeFact right is critical — it must enforce scope write permissions, estimate importance without external calls, and prepare for async enrichment (Phase 3).\n\n## Functions to Implement\n\n### Mutations\n\n1. storeFact — THE critical mutation\n   Args: content, source?, entityIds?, tags?, factType?, scopeId, createdBy, conversationId?, emotionalContext?\n   Logic:\n   a. Check write permission: call checkWriteAccess(scopeId, createdBy) — throw if unauthorized\n   b. Estimate importance: keyword-based scoring (no external calls)\n      - High (0.9): decision, error, critical, breaking, failed, security\n      - Medium (0.6): fix, implement, create, build, update, deploy\n      - Low (0.3): note, observation, maybe, consider, minor\n      - Default: 0.5\n   c. Insert fact with defaults: relevanceScore=1.0, accessedCount=0, lifecycleState=\"active\", embedding=undefined\n   d. Comment out enrichment scheduler: // await ctx.scheduler.runAfter(0, internal.actions.enrich.enrichFact, { factId })\n   e. Return { factId, importanceScore }\n\n2. bumpAccess(factId)\n   - Increment accessedCount by 1\n   - Recalculate relevanceScore (simple: min(1.0, 0.5 + accessedCount * 0.05))\n\n3. updateEnrichment(factId, updates) — internalMutation\n   - Patch fact with embedding, factualSummary, entityIds, temporalLinks, etc.\n   - Set updatedAt to Date.now()\n   - Used by Phase 3 enrichment pipeline\n\n### Queries\n\n4. getFact(factId) — query by Convex _id\n5. getByIds(factIds: Id\u003c\"facts\"\u003e[]) — query multiple facts\n6. getByScope(scopeId, limit?, factType?) — using by_scope index\n7. getByAgent(createdBy, limit?) — using by_agent index\n\n### Full-Text Search\n\n8. searchFacts(query, scopeId?, factType?, createdBy?, limit?)\n   - Uses searchIndex(\"search_content\")\n   - Filter by scopeId, factType, createdBy (all optional)\n   - Default limit: 10\n   - Returns matching facts sorted by relevance\n\n## storeFact Implementation Pattern (from detailed plan lines 269-308)\n\n```typescript\nexport const storeFact = mutation({\n  args: {\n    content: v.string(),\n    source: v.optional(v.string()),\n    entityIds: v.optional(v.array(v.string())),\n    tags: v.optional(v.array(v.string())),\n    factType: v.optional(v.string()),\n    scopeId: v.id(\"memory_scopes\"),\n    createdBy: v.string(),\n    conversationId: v.optional(v.id(\"conversations\")),\n    emotionalContext: v.optional(v.string()),\n  },\n  returns: v.object({ factId: v.id(\"facts\"), importanceScore: v.number() }),\n  handler: async (ctx, args) =\u003e {\n    // 1. Check write permission\n    const scope = await ctx.db.get(args.scopeId);\n    if (!scope) throw new Error(\"Scope not found\");\n    if (scope.writePolicy === \"members\" \u0026\u0026 !scope.members.includes(args.createdBy)) {\n      throw new Error(\"Agent not authorized to write to this scope\");\n    }\n    // ... (see Phase 1 plan for full implementation)\n  },\n});\n```\n\n## Full-Text Search Pattern\n\n```typescript\nexport const searchFacts = query({\n  args: {\n    query: v.string(),\n    scopeId: v.optional(v.id(\"memory_scopes\")),\n    factType: v.optional(v.string()),\n    createdBy: v.optional(v.string()),\n    limit: v.optional(v.number()),\n  },\n  handler: async (ctx, args) =\u003e {\n    let search = ctx.db.query(\"facts\").withSearchIndex(\"search_content\", (q) =\u003e {\n      let s = q.search(\"content\", args.query);\n      if (args.scopeId) s = s.eq(\"scopeId\", args.scopeId);\n      if (args.factType) s = s.eq(\"factType\", args.factType);\n      if (args.createdBy) s = s.eq(\"createdBy\", args.createdBy);\n      return s;\n    });\n    return await search.take(args.limit ?? 10);\n  },\n});\n```\n\n## Critical Constraints\n- Mutations retry automatically on transient errors — make storeFact idempotent-safe\n- Don't use console.log (reserved for MCP stdio in Phase 2) — use console.error for debugging\n- The enrichment scheduler call should be COMMENTED OUT in Phase 1 (action doesn't exist yet)\n- Use shared helper pattern for getFact (public query + internalQuery)\n- estimateImportance is a plain function, not a Convex function (no ctx needed)\n\n## Acceptance Criteria\n- [ ] storeFact mutation works with scope write permission check\n- [ ] storeFact rejects unauthorized writes (writePolicy: \"members\" with non-member)\n- [ ] getFact and getByIds return correct facts\n- [ ] searchFacts returns full-text search results with scope/type/agent filtering\n- [ ] bumpAccess increments count and updates relevanceScore\n- [ ] updateEnrichment (internal) can patch fact with enrichment data\n- [ ] estimateImportance returns correct scores for high/medium/low keywords\n\n## Estimate\n60 minutes","status":"closed","priority":0,"issue_type":"task","created_at":"2026-02-11T22:05:26.070928+01:00","updated_at":"2026-02-11T22:25:06.042923+01:00","closed_at":"2026-02-11T22:25:06.042925+01:00","dependencies":[{"issue_id":"engram-u51.4","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:05:26.071768+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.4","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:05:26.072955+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.4","depends_on_id":"engram-u51.3","type":"blocks","created_at":"2026-02-11T22:05:26.073956+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.5","title":"Implement entities CRUD with relationship graph","description":"# Implement Entities CRUD\n\n## What\nCreate convex/functions/entities.ts with CRUD operations for the entities table. Entities are named concepts (person, project, company, concept, tool) with a relationship graph.\n\n## Why\nEntities are the knowledge graph nodes in Engram. They represent people (Ryan, Indy), projects (OpenClaw, Engram), tools (Convex, LanceDB, Cohere), etc. Facts link to entities via entityIds array. The entity extraction pipeline (Phase 3) will auto-create entities from fact content.\n\n## Entity Schema (from PLAN.md)\n- entityId: string — human-readable ID like \"entity-ryan\", \"entity-convex\"\n- name: string — display name\n- type: string — person|project|company|concept|tool\n- firstSeen, lastSeen: number — timestamps\n- metadata: v.any() — flexible key-value store\n- relationships: array of {targetId, relationType, since?}\n  - Relation types: created_by|depends_on|works_with|part_of|related_to\n- importanceScore: float64\n- accessCount: number\n- createdBy: string — agent ID\n\n## Functions to Implement\n\n### Mutations\n1. upsert(entityId, name, type, metadata?, createdBy)\n   - Check if entity exists via by_entity_id index\n   - If exists: update lastSeen, merge metadata, increment accessCount\n   - If new: create with firstSeen=lastSeen=Date.now(), accessCount=1, relationships=[], importanceScore=0.5\n\n2. addRelationship(entityId, targetId, relationType, since?)\n   - Find entity via by_entity_id index\n   - Check for duplicate relationship (same targetId + relationType)\n   - Append to relationships array if new\n\n3. updateImportance(entityId, importanceScore) — internalMutation for Phase 3\n\n### Queries\n4. get(entityConvexId) — by Convex _id\n5. getByEntityId(entityId) — using by_entity_id index\n6. getByType(type, limit?) — using by_type index\n7. searchEntities(query, limit?) — full-text search on entity name\n\n## Technical Notes\n- entityId is the human-readable string (e.g., \"entity-ryan\"), NOT the Convex _id\n- The by_entity_id index enables O(1) lookup by string ID\n- metadata is v.any() for flexibility — stores arbitrary key-value data\n- Relationships form a directed graph: entity A relates_to entity B\n- The seed script will create initial entities using upsert\n\n## Acceptance Criteria\n- [ ] Can create new entity via upsert\n- [ ] Upsert on existing entity updates lastSeen and increments accessCount\n- [ ] Can add relationships between entities\n- [ ] Duplicate relationships are ignored (idempotent)\n- [ ] getByEntityId returns correct entity\n- [ ] searchEntities uses full-text search index on name field\n\n## Estimate\n30 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:05:44.180853+01:00","updated_at":"2026-02-11T22:25:06.177017+01:00","closed_at":"2026-02-11T22:25:06.177019+01:00","dependencies":[{"issue_id":"engram-u51.5","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:05:44.181937+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.5","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:05:44.183246+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.6","title":"Implement agents CRUD with registration","description":"# Implement Agents CRUD\n\n## What\nCreate convex/functions/agents.ts with CRUD operations for the agents table. Agents are the identities that interact with Engram memory.\n\n## Why\nEvery memory operation is attributed to an agent. Agent registration is the first step when an agent connects to Engram. The agents table tracks capabilities, last seen time, fact count, default scope, and optional telos (purpose/goal from PAI pattern).\n\n## Agent Schema (from PLAN.md)\n- agentId: string — human-readable like \"indy\", \"coder-1\", \"ml-worker\"\n- name: string — display name\n- nodeId: string? — OpenClaw node identifier\n- capabilities: string[] — what the agent can do\n- lastSeen: number — timestamp of last activity\n- factCount: number — total facts created by this agent\n- defaultScope: string — \"private\"|\"team\"|\"public\"\n- telos: string? — purpose/goal (PAI pattern, e.g., \"Ship code faster\")\n- settings: any? — agent-specific memory configuration\n\n## Functions to Implement\n\n### Mutations\n1. register(agentId, name, capabilities, defaultScope, nodeId?, telos?, settings?)\n   - Check if agent exists via by_agent_id index\n   - If exists: update lastSeen, capabilities, nodeId, telos, settings\n   - If new: create with lastSeen=Date.now(), factCount=0\n   - Also create private scope \"private-{agentId}\" if not exists\n   - Return agent Convex _id\n\n2. updateLastSeen(agentId) — called on every agent interaction\n   - Update lastSeen to Date.now()\n\n3. incrementFactCount(agentId) — internalMutation\n   - Increment factCount by 1 (called by storeFact)\n\n### Queries\n4. get(agentConvexId) — by Convex _id\n5. getByAgentId(agentId) — using by_agent_id index\n6. listAgents(limit?) — list all agents ordered by lastSeen\n\n## Technical Notes\n- Agent registration should be idempotent (re-registering updates, doesn't create duplicate)\n- The register mutation should also create the agent's private scope (depends on scopes CRUD existing, but can be done inline)\n- factCount is denormalized for quick access — incremented by storeFact\n- defaultScope determines where facts go when scopeId is not explicitly provided\n\n## Acceptance Criteria\n- [ ] Can register a new agent with capabilities and telos\n- [ ] Re-registration updates existing agent (idempotent)\n- [ ] updateLastSeen correctly timestamps\n- [ ] getByAgentId returns correct agent via index\n- [ ] listAgents returns agents sorted by lastSeen\n\n## Estimate\n25 minutes","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-11T22:06:00.876537+01:00","updated_at":"2026-02-11T22:25:06.309545+01:00","closed_at":"2026-02-11T22:25:06.309547+01:00","dependencies":[{"issue_id":"engram-u51.6","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:00.878563+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.6","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:00.88125+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.7","title":"Implement conversations CRUD with handoff tracking","description":"# Implement Conversations CRUD\n\n## What\nCreate convex/functions/conversations.ts for the conversations table. Conversations thread facts together, track participants, and record agent handoffs.\n\n## Why\nConversations provide temporal grouping of facts within a session. They track which agents participated and when handoffs occurred (Agent A passes context to Agent B). The threadFacts array links facts to their conversation for retrieval.\n\n## Schema (from PLAN.md)\n- sessionId: Id\u003c\"sessions\"\u003e\n- participants: string[] (agent IDs)\n- threadFacts: Id\u003c\"facts\"\u003e[] (linked facts)\n- contextSummary: string\n- importance: float64\n- tags: string[]\n- handoffs: array of {fromAgent, toAgent, timestamp, contextSummary}\n\n## Functions to Implement\n\n### Mutations\n1. create(sessionId, participants, contextSummary?, tags?) — create new conversation\n2. addFact(conversationId, factId) — append to threadFacts array\n3. addHandoff(conversationId, fromAgent, toAgent, contextSummary) — record agent handoff\n4. updateSummary(conversationId, contextSummary) — update context summary\n\n### Queries\n5. get(conversationId) — by Convex _id\n6. getBySession(sessionId) — using by_session index\n\n## Conversation Boundary Logic (from SpecFlow analysis)\n- Time gap \u003e 30 minutes OR agent explicitly calls boundary → new conversation\n- This logic lives in the MCP server (Phase 2), not in Convex functions\n\n## Acceptance Criteria\n- [ ] Can create conversations linked to sessions\n- [ ] Can add facts to conversation threadFacts\n- [ ] Can record handoffs between agents\n- [ ] getBySession returns conversations for a session\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:14.540067+01:00","updated_at":"2026-02-11T22:25:07.17318+01:00","closed_at":"2026-02-11T22:25:07.173182+01:00","dependencies":[{"issue_id":"engram-u51.7","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:14.541431+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.7","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:14.542843+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.8","title":"Implement sessions CRUD","description":"# Implement Sessions CRUD\n\n## What\nCreate convex/functions/sessions.ts for the sessions table. Sessions track agent activity periods.\n\n## Schema (from PLAN.md)\n- agentId: string\n- startTime: number\n- lastActivity: number\n- conversationIds: Id\u003c\"conversations\"\u003e[]\n- factCount: number\n- contextSummary: string\n- parentSession: Id\u003c\"sessions\"\u003e? (for nested/resumed sessions)\n- nodeId: string? (OpenClaw node)\n\n## Functions to Implement\n\n### Mutations\n1. create(agentId, contextSummary?, parentSession?, nodeId?) — start new session\n2. updateActivity(sessionId) — update lastActivity timestamp\n3. addConversation(sessionId, conversationId) — append to conversationIds\n4. incrementFactCount(sessionId) — internalMutation\n\n### Queries\n5. get(sessionId)\n6. getByAgent(agentId, limit?) — using by_agent index, ordered by startTime\n7. getActive(agentId) — most recent session for an agent\n\n## Acceptance Criteria\n- [ ] Can create sessions linked to agents\n- [ ] updateActivity correctly timestamps\n- [ ] getByAgent returns sessions ordered by startTime\n- [ ] getActive returns the most recent session\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:26.582497+01:00","updated_at":"2026-02-11T22:25:07.321437+01:00","closed_at":"2026-02-11T22:25:07.32144+01:00","dependencies":[{"issue_id":"engram-u51.8","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:26.583468+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.8","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:26.584755+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u51.9","title":"Implement signals CRUD for feedback tracking","description":"# Implement Signals CRUD\n\n## What\nCreate convex/functions/signals.ts for the signals table. Signals capture feedback on facts — explicit ratings and implicit sentiment from the PAI feedback loop pattern.\n\n## Why\nSignals are how agents communicate which memories were useful. This enables learned utility scoring (MemRL pattern) in later phases. The PAI system uses explicit ratings (1-10) and implicit sentiment (-1.0 to 1.0) to steer memory retrieval.\n\n## Schema (from PLAN.md)\n- factId: Id\u003c\"facts\"\u003e? (optional — some signals are session-level)\n- sessionId: Id\u003c\"sessions\"\u003e? (optional)\n- agentId: string\n- signalType: string — explicit_rating|implicit_sentiment|failure\n- value: number — 1-10 for ratings, -1.0 to 1.0 for sentiment\n- comment: string?\n- confidence: float64?\n- context: string?\n- timestamp: number\n\n## Functions to Implement\n\n### Mutations\n1. recordSignal(factId?, sessionId?, agentId, signalType, value, comment?, confidence?, context?)\n   - Validate: at least one of factId or sessionId must be provided\n   - Validate: value range depends on signalType (1-10 for rating, -1.0-1.0 for sentiment)\n   - Set timestamp to Date.now()\n\n### Queries\n2. getByFact(factId, limit?) — using by_fact index\n3. getByAgent(agentId, limit?) — using by_agent index\n4. getByType(signalType, limit?) — using by_type index\n\n## Acceptance Criteria\n- [ ] Can record signals with fact or session reference\n- [ ] Validation rejects signals without factId AND sessionId\n- [ ] getByFact returns signals for a specific fact\n- [ ] getByAgent returns signals from a specific agent\n\n## Estimate\n20 minutes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-11T22:06:39.616471+01:00","updated_at":"2026-02-11T22:25:07.467715+01:00","closed_at":"2026-02-11T22:25:07.467719+01:00","dependencies":[{"issue_id":"engram-u51.9","depends_on_id":"engram-u51","type":"parent-child","created_at":"2026-02-11T22:06:39.617434+01:00","created_by":"Ryan Lisse"},{"issue_id":"engram-u51.9","depends_on_id":"engram-u51.2","type":"blocks","created_at":"2026-02-11T22:06:39.618846+01:00","created_by":"Ryan Lisse"}]}
{"id":"engram-u6o","title":"Phase 4: Multi-Agent + Crons — multi-scope recall, 7 cron jobs, handoff tracking","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:51:00.561603+01:00","updated_at":"2026-02-12T10:06:05.587025+01:00","closed_at":"2026-02-12T10:06:05.587025+01:00","close_reason":"Completed"}
{"id":"engram-uah","title":"Vault file watcher: MD→Convex bidirectional import","description":"Vault file watcher for bidirectional sync (integrated in vault-sync daemon):\n\n**Implementation (part of mcp-server/src/daemons/vault-sync.ts from engram-7yr):**\n\nUsing chokidar to watch vault/ directory:\n- Watch patterns: vault/**/*.md (ignore dot files)\n- Events: change, add (not delete - archive in DB instead)\n- Options: ignoreInitial: true (don't trigger on startup), persistent: true\n\n**On file change:**\n1. Read file content\n2. Parse frontmatter + body\n3. Extract fact ID from frontmatter.id\n4. Call reconcileFromVault action (from engram-8nz)\n5. If conflicts detected: create .conflict file\n6. If success: log sync event\n\n**Error handling:**\n- Parse errors: log + skip file\n- Missing ID: log warning + skip\n- Convex connection errors: exponential backoff retry\n- File permission errors: log + skip\n\n**Reconciliation flow:**\nvault file edited → chokidar detects change → reconcileFromVault action → three-way merge → DB updated OR conflict file created\n\n**Performance:**\n- Event handling \u003c100ms\n- Reconciliation \u003c200ms p95\n- No blocking of other daemon operations\n\n**Tests:** file-watcher-e2e.test.ts (edit file → event triggered → DB updated), conflict-detection-e2e.test.ts (concurrent edits → conflict file)\nRef: VAULT_INTEGRATION_PLAN.md Phase 3.3, Phase 3.4","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-14T22:57:02.366752+01:00","updated_at":"2026-02-14T23:06:46.779576+01:00","dependencies":[{"issue_id":"engram-uah","depends_on_id":"engram-dxj","type":"blocks","created_at":"2026-02-14T22:57:23.950393+01:00","created_by":"daemon"},{"issue_id":"engram-uah","depends_on_id":"engram-8nz","type":"blocks","created_at":"2026-02-14T23:07:58.964782+01:00","created_by":"daemon"}]}
{"id":"engram-uqr","title":"Phase 2: MCP Server — 12 tools, stdio transport, ConvexHttpClient","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T09:50:57.325257+01:00","updated_at":"2026-02-12T10:06:05.281267+01:00","closed_at":"2026-02-12T10:06:05.281267+01:00","close_reason":"Completed"}
{"id":"engram-vj6","title":"MCP tools: query_vault + memory_export_graph","description":"New MCP tools for vault querying and graph export:\n\n**1. memory_query_vault (mcp-server/src/tools/query-vault.ts):**\n- Direct vault file queries without Convex\n- Parameters: query (string), filters (type, priority, scope)\n- Scan vault index files for matches\n- Load facts from markdown files\n- Use case: Fast local queries when Convex unavailable\n- Returns: facts[], source: 'vault', latencyMs\n\n**2. memory_export_graph (mcp-server/src/tools/export-graph.ts):**\n- Export memory graph to Obsidian-compatible JSON\n- Uses graph-exporter.ts (in engram-43e)\n- Parameters: outputPath (default: vault/.obsidian/graph.json)\n- Format: {nodes: [{id, label, type, group}], links: [{source, target, type}]}\n- Includes fact→entity edges (type: 'mentions')\n- Includes entity→entity edges (type: relationship type)\n- Use case: Obsidian graph visualization\n- Returns: {success, nodeCount, linkCount, outputPath}\n\n**MCP server registration (mcp-server/src/index.ts):**\n- Register both tools with MCP protocol\n- Add to tool list in server initialization\n\n**Tests:** query-vault.test.ts (vault queries work), export-graph.test.ts (valid Obsidian JSON format)\n**Performance:** Query vault \u003c150ms, graph export \u003c2s for 10k facts\nRef: VAULT_INTEGRATION_PLAN.md Phase 1.3.2, Phase 4.5","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:31.532522+01:00","updated_at":"2026-02-14T23:06:13.023375+01:00","dependencies":[{"issue_id":"engram-vj6","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:44.167653+01:00","created_by":"daemon"},{"issue_id":"engram-vj6","depends_on_id":"engram-gxr","type":"blocks","created_at":"2026-02-14T23:02:12.639062+01:00","created_by":"daemon"}]}
{"id":"engram-waf","title":"Create vault-format.ts: Fact↔Markdown serialization","description":"Create mcp-server/src/lib/vault-format.ts with comprehensive markdown serialization:\n\n**Main Functions:**\n1. generateFrontmatter(fact) — Convert fact to YAML frontmatter with all fields (id, type, scope, priority, lifecycleState, tags, entities, timestamps, importance, confidence, importanceTier, vaultPath, observationTier, etc.). Omit null/undefined. Format dates as ISO 8601.\n2. generateMarkdownBody(fact) — Convert content to markdown with H1 title, context blockquote, main content, Related Facts section (wiki-links), Entities section, Provenance footer.\n3. parseFrontmatter(fileContent) — Parse YAML + body, validate required fields, convert date strings to Date objects, handle malformed YAML gracefully, return {frontmatter, body, errors}.\n4. generateFilename(fact) — Format: {slugified-title}-{short-id}.md (max 50 chars slug, 8-char convexId prefix). Use slugify npm package.\n5. computeFolderPath(fact, vaultRoot) — Route by factType using FACT_TYPE_TO_FOLDER map from spec §1.2. Scope prefix: private-{agentId}/, team-{teamId}/, etc.\n6. extractWikiLinks(content) — Find all [[Name]] links, return array of {name, startIndex, endIndex}.\n\n**Dependencies:** js-yaml, slugify\n**Tests:** Unit tests for each function, golden tests for round-trip (fact → markdown → fact)\n**Performance target:** Format/parse \u003c10ms per fact\nRef: specs/obsidian-mirror-plan.md §1.1-1.3, Phase 2","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:13.806981+01:00","updated_at":"2026-02-14T23:08:51.006911+01:00","dependencies":[{"issue_id":"engram-waf","depends_on_id":"engram-ywx","type":"blocks","created_at":"2026-02-14T22:57:17.70699+01:00","created_by":"daemon"},{"issue_id":"engram-waf","depends_on_id":"engram-46g","type":"blocks","created_at":"2026-02-14T23:07:29.234192+01:00","created_by":"daemon"}]}
{"id":"engram-wzv","title":"Phase 6: Migration + Polish — import, crons, benchmarks","status":"closed","priority":0,"issue_type":"epic","created_at":"2026-02-12T10:02:09.557812+01:00","updated_at":"2026-02-12T10:07:30.097634+01:00","closed_at":"2026-02-12T10:07:30.097634+01:00","close_reason":"Completed"}
{"id":"engram-ykh","title":"Entity backlinks + graph edge consistency","description":"Entity backlinks consistency and graph edge validation:\n\n**This task focuses on maintaining consistency between:**\n1. Fact content wiki-links [[Entity]]\n2. Entity backlinks array in entities table\n3. Fact entities array field\n4. Graph export edges\n\n**Implementation (convex/functions/entities.ts):**\n\n1. updateBacklinks(factId, entityNames):\n   - For each entity name in the fact\n   - Find entity by name\n   - Add to entity.backlinks if not exists: {factId, factType, linkedAt}\n   - Remove from backlinks if entity no longer mentioned\n\n2. validateBacklinks() — Periodic validation:\n   - For each entity, check backlinks array\n   - Verify each backlinked fact still exists and mentions entity\n   - Remove stale backlinks (fact deleted or entity removed)\n   - Log inconsistencies\n\n3. rebuildBacklinks() — Full rebuild:\n   - Clear all entity.backlinks arrays\n   - Scan all active facts\n   - Extract wiki-links from content\n   - Rebuild backlinks from scratch\n   - Use case: Fix inconsistencies after bugs\n\n**Integration points:**\n- storeFact: call updateBacklinks after insert\n- updateFact: call updateBacklinks after update\n- deleteFact: call updateBacklinks to remove\n\n**Convex cron (optional):**\n- Schedule validateBacklinks() daily\n- Fix inconsistencies automatically\n- Log warnings for manual review\n\n**Tests:** backlink-consistency.test.ts (store/update/delete maintains consistency), backlink-validation.test.ts (detect and fix stale backlinks)\n**Performance:** Update backlinks \u003c50ms, full rebuild \u003c30s for 10k entities\nRef: VAULT_INTEGRATION_PLAN.md Phase 4.4","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-14T23:00:31.71662+01:00","updated_at":"2026-02-14T23:07:03.730847+01:00","dependencies":[{"issue_id":"engram-ykh","depends_on_id":"engram-43e","type":"blocks","created_at":"2026-02-14T23:01:58.67423+01:00","created_by":"daemon"}]}
{"id":"engram-ywx","title":"Schema changes: add vault mirror fields to facts table","description":"Add vault mirror fields to convex/schema.ts facts table:\n\n**New fields:**\n1. vaultPath (v.optional(v.string())) — Relative path in vault (e.g., \"private-indy/decisions/2026-02-14-foo.md\")\n2. vaultSyncedAt (v.optional(v.number())) — Last sync timestamp\n3. confidence (v.optional(v.float64())) — 0.0-1.0 confidence score (from spec §1.4)\n4. importanceTier (v.optional(v.string())) — \"structural\"|\"potential\"|\"contextual\"\n5. observationTier (v.optional(v.string())) — \"critical\"|\"notable\"|\"background\" (flat field, no dot notation)\n6. observationCompressed (v.optional(v.boolean())) — Whether background compression ran\n7. observationOriginalContent (v.optional(v.string())) — Content before compression\n\n**New indices:**\n- .index(\"by_vault_path\", [\"vaultPath\"])\n- .index(\"by_vault_synced\", [\"vaultSyncedAt\"])\n- .index(\"by_observation_tier\", [\"observationTier\", \"timestamp\"])\n- .index(\"unmirrored\", [\"vaultPath\", \"lifecycleState\"])\n\nNOTE: Convex does not support dot-notation field names. All observation.* fields from the original plan are flattened to observationTier, observationCompressed, observationOriginalContent.\nNOTE: facts table uses \"timestamp\" not \"createdAt\", and \"lifecycleState\" not \"status\".\n\nPerformance target: Schema migration \u003c1s, zero downtime.\nRef: specs/obsidian-mirror-plan.md §1.4, VAULT_INTEGRATION_PLAN.md Phase 1.3.1, Phase 2.8, Phase 6.8","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-14T22:56:07.968133+01:00","updated_at":"2026-02-14T23:07:41.904606+01:00"}
